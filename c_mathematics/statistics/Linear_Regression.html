

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Linear regression &#8212; ESE Jupyter Material</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/mystnb.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".cell"
        const thebe_selector_input = ".cell_input div.highlight"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Introduction to statistics for Geoscientists" href="Statistics_for_Geoscientists.html" />
    <link rel="prev" title="Statistics" href="intro.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ESE Jupyter Material</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../../intro.html">Landing page</a>
  </li>
  <li class="">
    <a href="../../a_modules/intro.html">Modules</a>
  </li>
  <li class="">
    <a href="../../b_coding/intro.html">Coding</a>
  </li>
  <li class="active">
    <a href="../intro.html">Mathematics</a>
  <ul class="nav sidenav_l2">
    <li class="">
      <a href="../calculus/intro.html">Calculus</a>
    </li>
    <li class="">
      <a href="../complex_analysis/intro.html">Complex analysis</a>
    </li>
    <li class="">
      <a href="../differential_equations/intro.html">Differential equations</a>
    </li>
    <li class="">
      <a href="../linear_algebra/intro.html">Linear algebra</a>
    </li>
    <li class="">
      <a href="../mathematical_notation/intro.html">Mathematical notation</a>
    </li>
    <li class="">
      <a href="../numerical_methods/intro.html">Numerical methods</a>
    </li>
    <li class="">
      <a href="../series_and_sequences/intro.html">Series and sequences</a>
    </li>
    <li class="">
      <a href="../sets_and_functions/intro.html">Sets and functions</a>
    </li>
    <li class="active">
      <a href="intro.html">Statistics</a>
      <ul class="nav sidenav_l3">
      <li class="active">
        <a href="">Linear regression</a>
      </li>
      <li class="">
        <a href="Statistics_for_Geoscientists.html">Introduction to statistics for Geoscientists</a>
      </li>
    </ul>
    </li>
  </ul>
  </li>
  <li class="">
    <a href="../../d_geosciences/intro.html">Geosciences</a>
  </li>
  <li class="">
    <a href="../../e_extra/intro.html">Further resources</a>
  </li>
  <li class="">
    <a href="../../genindex.html">Index</a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/c_mathematics/statistics/Linear_Regression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        <a class="issues-button"
            href="https://github.com/primer-computational-mathematics/book/issues/new?title=Issue%20on%20page%20%2Fc_mathematics/statistics/Linear_Regression.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/primer-computational-mathematics/book/master?urlpath=tree/notebooks/c_mathematics/statistics/Linear_Regression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#theory" class="nav-link">Theory</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#simple-linear-regression" class="nav-link">Simple linear regression</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#multiple-linear-regression" class="nav-link">Multiple linear regression</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#root-mean-square-error" class="nav-link">Root-mean-square error</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#coefficient-of-determination" class="nav-link">Coefficient of determination</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#least-squares-error-calculation" class="nav-link">Least  squares error calculation</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#implementation-of-linear-regression-in-python" class="nav-link">Implementation of linear regression in Python</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#simple-example-submarine-landslide-size-in-the-north-atlantic" class="nav-link">Simple example - submarine landslide size in the North Atlantic</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#polynomial-curve-fitting" class="nav-link">Polynomial curve fitting</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#references" class="nav-link">References</a>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="linear-regression">
<span id="linear-regress"></span><h1>Linear regression<a class="headerlink" href="#linear-regression" title="Permalink to this headline">¶</a></h1>
<div class="section" id="theory">
<span id="index-0"></span><h2>Theory<a class="headerlink" href="#theory" title="Permalink to this headline">¶</a></h2>
<p>Linearity refers to a linear relationship between two or more variables. Linear regression aims to predict the dependent variable value (\(y\)) based on a given independent variable (\(x\)). Therefore, linear regression finds out a linear relationship between \(x\) and \(y\).</p>
<p>With noisy data or multiple different measurements of \(y\) at a given value of \(x\), we may not be able to fit a function/curve that goes through all points exactly. Therefore, in linear regresssion the aim is to find a function that best approximates the data but does not necessarily go through all the points.</p>
<div class="section" id="simple-linear-regression">
<h3>Simple linear regression<a class="headerlink" href="#simple-linear-regression" title="Permalink to this headline">¶</a></h3>
<p>Plotting the independent variable \(x\) on the x-axis and dependent variable \(y\) on the y-axis, linear regression gives us a straight line with equation:
\[y=b_0+b_1x,\]
where \(b_0\) is the intercept and \(b_1\) is the slope of the line. The \(x\) and \(y\) variables remain the same as the data points cannot change, however, the intercept (\(b_0\)) and slope (\(b_1\)) can be modified to obtain the most optimal value for the intercept and the slope. The linear regression algorithm fits multiple lines on the data points and returns the line that results in the smallest error. This may be achieved by minimising the sum of the squares of the differences to the data, known as a least squares approximation.</p>
<p><a class="reference external" href="https://acadgild.com/blog/2linear-regression-case-study-2"><img src="https://s3.amazonaws.com/acadgildsite/wordpress_images/Data+Science/2Linear+regression+Case+Study+2/blogs+LR+2+pic+1.png" style="width:300px;"/></a></p>
<p>Figure 1: Plot of scatter points in 2D space (blue) and line that results in the least error (red).</p>
</div>
<div class="section" id="multiple-linear-regression">
<h3>Multiple linear regression<a class="headerlink" href="#multiple-linear-regression" title="Permalink to this headline">¶</a></h3>
<p>This can be extended to multiple linear regression where there are more than two variables. In this scenario, the dependent variable is dependent upon several independent variables \(x= (x_1, …, x_n)\) where \(n\) is the number of variables. You can assume a linear relationship between \(x\) and \(y\) with the regression equation:
\[y=b_0+b_1x_1+b_2x_2+b_3x_3+…b_nx_n +\epsilon,\]
where \(b_0,b_1,…,b_n\) are the regression coefficients and \(\epsilon\) is the random error.</p>
</div>
<div class="section" id="root-mean-square-error">
<h3>Root-mean-square error<a class="headerlink" href="#root-mean-square-error" title="Permalink to this headline">¶</a></h3>
<p id="index-1">There are many methods to evaluate the performance of the linear regression algorithm. Two commonly used methods are the <a class="reference external" href="https://en.wikipedia.org/wiki/Root-mean-square_deviation">root-mean-square error</a> (RMSE) and the <a class="reference external" href="https://en.wikipedia.org/wiki/Coefficient_of_determination">coefficient of determination</a> (\(R^2\) score).</p>
<p>RMSE is the square root of the sum of all errors squared divided by the number of values. The equation for the RMSE is:
\[RMSE=\sqrt{\frac{1}{n}\sum_{i=1}^{n} (\hat{y_i} - y_i)^2},\]
where \(\hat{y_1}, \hat{y_2}, …, \hat{y_n}\)  are the predicted values, \(y_1, y_2, …, y_n\) are the observed values and \(n\) is the number of observations.</p>
</div>
<div class="section" id="coefficient-of-determination">
<h3>Coefficient of determination<a class="headerlink" href="#coefficient-of-determination" title="Permalink to this headline">¶</a></h3>
<p id="index-2">The coefficient of determinaion is a statistical measure of how close the data are to the linear regression line.</p>
<p>\[R^2 = \frac{\text{Explained variation}}{\text{Total variation}}.\]</p>
<p>\(R^2\) is therefore always between 0 and 100%. The higher the \(R^2\), the better the model fits the data.</p>
<p>\(R^2\) is defined as follows:
\[R^2 = 1-\frac{SS_r}{SS_t},\\
SS_r=\sum_{i=1}^{n} ({y_i} - \hat{y_i})^2,\\
SS_t=\sum_{i=1}^{n} ({y_i} - \bar{y_i})^2.\]</p>
<p>\(SS_r\) is the sum of squared regression and represents the variation explained by the linear regression model.</p>
<p>\(SS_t\) is the sum of squared yotal and represents the total variation in the data.</p>
<p>\(y_1, y_2, …, y_n\) are the observed values, \(\hat{y_1}, \hat{y_2}, …, \hat{y_n}\)  are the predicted values of \(y\), and \(\bar{y_1}, \bar{y_2}, …, \bar{y_n}\) are the mean values of \(y\).</p>
<p>Based on the above equation the \(R^2\) score usually ranges from 0 to 1, but can be negative if the model is completely wrong.</p>
</div>
<div class="section" id="least-squares-error-calculation">
<h3>Least  squares error calculation<a class="headerlink" href="#least-squares-error-calculation" title="Permalink to this headline">¶</a></h3>
<p>Least squares fitting minimises the sum of the squares of the differences between the data provided and the polynomial approximation. In other words it minimises the folowing expression:</p>
<p>\[E=\sum_{i=0}^{N} (P(x_i) - y_i)^2,\]</p>
<p>where \(E\) is the squared error, \(P(x_i)\) is the value of the polynomial function that has been fit to the data evaluated at point \(x_i\), and \(y_i\) is the \(i^{th}\) data value.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Linear_least_squares"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Linear_least_squares_example2.svg/440px-Linear_least_squares_example2.svg.png" style="width:300px;"/></a></p>
<p>Figure 2: A plot of the data points (red), the least squares line of best fit (blue), and the residuals (green).</p>
<p>In this calulation we are computing the sum of the squares of the distances indicated in green in Figure 1.</p>
</div>
</div>
<div class="section" id="implementation-of-linear-regression-in-python">
<h2>Implementation of linear regression in Python<a class="headerlink" href="#implementation-of-linear-regression-in-python" title="Permalink to this headline">¶</a></h2>
<div class="section" id="simple-example-submarine-landslide-size-in-the-north-atlantic">
<h3>Simple example - submarine landslide size in the North Atlantic<a class="headerlink" href="#simple-example-submarine-landslide-size-in-the-north-atlantic" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Some imports needed for linear regression in python</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">scipy.interpolate</span> <span class="k">as</span> <span class="nn">si</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">ss</span>

<span class="c1"># Some default font sizes for plots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.sans-serif&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Arial&#39;</span><span class="p">,</span> <span class="s1">&#39;Dejavu Sans&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>In this example we are attempting to fit a linear best fit line to the data <code class="docutils literal notranslate"><span class="pre">length_width.dat</span></code> in log-log space. This file contains the lengths and widths of submarine landslides in the North Atlantic basin from Fig. 7 in <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0025322704002774">Huhnerbach &amp; Masson (2004)</a>.</p>
<p>Firstly, we will use <code class="docutils literal notranslate"><span class="pre">numpy.polyfit</span></code> in order to carry out the least squares error calculation to fit a linear polynomial. Next, we will use <code class="docutils literal notranslate"><span class="pre">scipy.stats.linregress</span></code> to perform linear regression using a <a class="reference external" href="https://www.scipy.org/">SciPy</a> implementation of linear regression. Then, we will compare the slope and the intercept (the two coefficients in the linear polynomial) between the two approaches.</p>
<p>The coefficient of determination is also determined by default from the linear regression calculation. To check these values agree we will also calculate the \(R^2\) value using the <code class="docutils literal notranslate"><span class="pre">numpy.polyfit</span></code> data.</p>
<p>Let’s define a function to evaluate squared error:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Function to evaluate the squared error</span>
<span class="k">def</span> <span class="nf">sqr_error</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">xi</span><span class="p">,</span> <span class="n">yi</span><span class="p">):</span>
    
    <span class="sd">&quot;&quot;&quot;&quot;Function to evaluate the sum of square of errors&quot;&quot;&quot;</span>
    
    <span class="c1"># Compute the square of the differences</span>
    <span class="n">diff2</span> <span class="o">=</span> <span class="p">(</span><span class="n">p</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span><span class="o">-</span><span class="n">yi</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
    
    <span class="c1"># Return their sum</span>
    <span class="k">return</span> <span class="n">diff2</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Open a file and store data in arrays:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;length_width.dat&quot;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>

<span class="n">xi</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">yi</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">xi</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">yi</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]))</span>
    
<span class="n">xi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span>
<span class="n">yi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">yi</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Perform linear regression and plot the results:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set up figure</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>

<span class="c1"># Plot the raw data</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">loglog</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">yi</span><span class="p">,</span> <span class="s1">&#39;ko&#39;</span><span class="p">)</span>

<span class="c1"># Fit a linear line to the log of the data using numpy.polyfit</span>
<span class="n">logxi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">xi</span><span class="p">)</span>
<span class="n">logyi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">yi</span><span class="p">)</span>
<span class="n">poly_coeffs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">logxi</span><span class="p">,</span> <span class="n">logyi</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Construct the corresponding polynomial function from these coefficients</span>
<span class="n">p1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">poly_coeffs</span><span class="p">)</span>
<span class="c1"># print the polynomial coefficients to compare with regression</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Lagrange polynomial coefficients = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">poly_coeffs</span><span class="p">))</span>

<span class="c1">#Calculate and print an R-squared value for this fit using the mathematical</span>
<span class="c1"># definition from https://en.wikipedia.org/wiki/Coefficient_of_determination</span>
<span class="n">SS_res</span> <span class="o">=</span> <span class="n">sqr_error</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">logxi</span><span class="p">,</span> <span class="n">logyi</span><span class="p">)</span>
<span class="n">SS_tot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logyi</span><span class="p">)</span> <span class="o">-</span> <span class="n">logyi</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">r2</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="n">SS_res</span><span class="o">/</span><span class="n">SS_tot</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R^2 value calculated from Lagrange polynomial fit to the data in log-log space = </span><span class="si">{}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2</span><span class="p">))</span>

<span class="c1"># Only need two points to plot the regression</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">xi</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">xi</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">loglog</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p1</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\log(y) = $</span><span class="si">%.3f</span><span class="s1">$\,\log(x) + $</span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span>
           <span class="p">(</span><span class="n">poly_coeffs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">poly_coeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># Check values computed above against scipy&#39;s linear regression</span>
<span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">std_err</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">logxi</span><span class="p">,</span> <span class="n">logyi</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Linear regression: slope, intercept, r_value = </span><span class="si">{0:.8f}</span><span class="s1">, </span><span class="si">{1:.8f}</span><span class="s1">, </span><span class="si">{2:.8f}</span><span class="s1">&#39;</span>\
      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r_value</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;R^2 = </span><span class="si">{:.8f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r_value</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Submarine landslide dimensions&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Length [km]&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Width [km]&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.76</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="s1">&#39;R2 = </span><span class="si">%.6f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">r2</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">ax1</span><span class="o">.</span><span class="n">transAxes</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Lagrange polynomial coefficients = [1.0266104  0.37698383]
R^2 value calculated from Lagrange polynomial fit to the data in log-log space = 0.5653751967433511

Linear regression: slope, intercept, r_value = 1.02661040, 0.37698383, 0.75191435
R^2 = 0.56537520
</pre></div>
</div>
<img alt="../../_images/Linear_Regression_8_1.png" src="../../_images/Linear_Regression_8_1.png" />
</div>
</div>
</div>
<div class="section" id="polynomial-curve-fitting">
<h3>Polynomial curve fitting<a class="headerlink" href="#polynomial-curve-fitting" title="Permalink to this headline">¶</a></h3>
<p>Curve fitting is popular to use for datasets containing noise. To fit these curves of varying polynomial degree we can again use the least squares error calculation.</p>
<p>Using <code class="docutils literal notranslate"><span class="pre">numpy.polyfit</span></code> we can fit curves of varying polynomial degree to the data points. This is demonstrated below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Data points</span>
<span class="n">xi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">])</span>
<span class="n">yi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">])</span>

<span class="c1"># Let&#39;s set up some space to store all the polynomial coefficients</span>
<span class="c1"># there are some redundancies here, and we have assumed we will only </span>
<span class="c1"># consider polynomials up to degree N</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">poly_coeffs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">poly_coeffs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">yi</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;poly_coeffs = </span><span class="se">\n</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">poly_coeffs</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>poly_coeffs = 
[[ 0.5         0.          0.          0.          0.          0.        ]
 [ 0.0508044   0.26714649  0.          0.          0.          0.        ]
 [ 0.02013603 -0.13983999  0.55279339  0.          0.          0.        ]
 [-0.00552147  0.09889271 -0.43193108  0.75909819  0.          0.        ]
 [-0.00420655  0.07403681 -0.38492428  0.59251888  0.27906056  0.        ]
 [-0.00301599  0.06536037 -0.49614427  1.59623195 -2.08266478  1.20030166]]
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">margins</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">9.1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">poly_coeffs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)])</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Degree </span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <span class="n">yi</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;raw data&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Polynomial approximations of differing degree&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Linear_Regression_11_0.png" src="../../_images/Linear_Regression_11_0.png" />
</div>
</div>
<p>Using the above function that evaluates the squared error, we can evaluate the error for each of the polynomials calculated above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">poly_coeffs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Square of the difference between the data and the &#39;</span>
          <span class="s1">&#39;polynomial of degree </span><span class="si">{0:1d}</span><span class="s1"> = </span><span class="si">{1:.8e}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">sqr_error</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">xi</span><span class="p">,</span> <span class="n">yi</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Square of the difference between the data and the polynomial of degree 0 = 4.60000000e-01.
Square of the difference between the data and the polynomial of degree 1 = 3.32988992e-01.
Square of the difference between the data and the polynomial of degree 2 = 1.99478242e-01.
Square of the difference between the data and the polynomial of degree 3 = 1.57303437e-01.
Square of the difference between the data and the polynomial of degree 4 = 4.69232378e-02.
Square of the difference between the data and the polynomial of degree 5 = 1.75525473e-26.
</pre></div>
</div>
</div>
</div>
<p>As can be seen above the error drops as we approximate the data with higher degree polynomials.</p>
<p>For some inspiration on multiple linear regression, you can look at <a class="reference external" href="https://towardsdatascience.com/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-83a8f7ae2b4f">“A beginner’s guide to linear regression in Python with Scikit-Learn”</a> and <a class="reference external" href="https://acadgild.com/blog/2linear-regression-case-study-2">“Linear regression case study”</a>.</p>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Information in this notebook is compiled based on ACSE-3 (Numerical Methods), Lecture 1: Interpolation and Curve Fitting</p></li>
<li><p>V. Huhnerbach, D.G. Masson, Landslides in the North Atlantic and its adjacent seas: an analysis of their morphology, setting and behaviour, Marine Geology 213 (2004) 343 – 362.</p></li>
<li><p>Real Python - <a class="reference external" href="https://realpython.com/linear-regression-in-python/">“Linear regression in Python”</a></p></li>
<li><p>Towards Data Science - <a class="reference external" href="https://towardsdatascience.com/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-83a8f7ae2b4f">“A beginner’s guide to linear regression in Python with Scikit-Learn”</a> and <a class="reference external" href="https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e">“What does RMSE really mean?”</a></p></li>
<li><p>Acadgild - <a class="reference external" href="https://acadgild.com/blog/2linear-regression-case-study-2">“Linear regression case study”</a></p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "primer-computational-mathematics/book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./c_mathematics/statistics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">Statistics</a>
    <a class='right-next' id="next-link" href="Statistics_for_Geoscientists.html" title="next page">Introduction to statistics for Geoscientists</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Imperial College London<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
  </body>
</html>