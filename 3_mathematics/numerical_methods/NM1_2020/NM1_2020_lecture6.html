

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Numerical Methods &#8212; ESE Jupyter Material</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/sphinx-book-theme.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/language_data.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/mystnb.js"></script>
    <script src="../../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".cell"
        const thebe_selector_input = ".cell_input div.highlight"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
  
  <img src="../../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ESE Jupyter Material</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../../../intro.html">Landing page</a>
  </li>
  <li class="">
    <a href="../../../2_coding/intro.html">Coding</a>
  </li>
  <li class="">
    <a href="../../intro.html">Mathematics</a>
  </li>
  <li class="">
    <a href="../../../1_modules/intro.html">Modules</a>
  </li>
  <li class="">
    <a href="../../../4_geosciences/intro.html">Geosciences</a>
  </li>
  <li class="">
    <a href="../../../5_extra/intro.html">Extra resources for researchers</a>
  </li>
  <li class="">
    <a href="../../../genindex.html">Index</a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/3_mathematics/numerical_methods/NM1_2020/NM1_2020_lecture6.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        <a class="issues-button"
            href="https://github.com/primer-computational-mathematics/book/issues/new?title=Issue%20on%20page%20%2F3_mathematics/numerical_methods/NM1_2020/NM1_2020_lecture6.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/primer-computational-mathematics/book/master?urlpath=tree/notebooks/3_mathematics/numerical_methods/NM1_2020/NM1_2020_lecture6.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#" class="nav-link">Numerical Methods</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#lecture-6-numerical-linear-algebra-ii" class="nav-link">Lecture 6: Numerical Linear Algebra II</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#contents" class="nav-link">Contents</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#i-what-are-matrices" class="nav-link">I.   What are Matrices?</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#ii-introduction-to-lu-decomposition" class="nav-link">II.  Introduction to LU Decomposition</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#iii-lu-decomposition-doolittle-algorithm" class="nav-link">III. LU Decomposition Doolittle Algorithm</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#iv-lu-decomposition-implementation" class="nav-link">IV. LU Decomposition Implementation</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#v-partial-pivoting" class="nav-link">V.  Partial Pivoting</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#learning-objectives" class="nav-link">Learning objectives:</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#id1" class="nav-link">I.   What are Matrices?</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#introduction-to-lu-decomposition" class="nav-link">Introduction to LU Decomposition</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#lu-decomposition-motivation" class="nav-link">LU decomposition - motivation</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#lu-decomposition-theory" class="nav-link">LU decomposition - theory</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#lu-decomposition-doolittle-algorithm" class="nav-link">LU Decomposition Doolittle Algorithm</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#span-style-color-blue-exercise-6-1-lower-triangular-matrices-span" class="nav-link"><span style="color:blue">Exercise 6.1: lower-triangular matrices</span></a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#lu-decomposition-implementation" class="nav-link">LU Decomposition Implementation</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#span-style-color-blue-exercise-6-2-lu-decomposition-span" class="nav-link"><span style="color:blue">Exercise 6.2: LU decomposition</span></a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#id2" class="nav-link">V.  Partial Pivoting</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#span-style-color-blue-exercise-6-3-partial-pivoting-span" class="nav-link"><span style="color:blue">Exercise 6.3: Partial pivoting</span></a>
        </li>
    
            </ul>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="numerical-methods">
<h1>Numerical Methods<a class="headerlink" href="#numerical-methods" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="lecture-6-numerical-linear-algebra-ii">
<h1>Lecture 6: Numerical Linear Algebra II<a class="headerlink" href="#lecture-6-numerical-linear-algebra-ii" title="Permalink to this headline">¶</a></h1>
<div class="section" id="contents">
<h2>Contents<a class="headerlink" href="#contents" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="i-what-are-matrices">
<h2>I.   What are Matrices?<a class="headerlink" href="#i-what-are-matrices" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="ii-introduction-to-lu-decomposition">
<h2>II.  Introduction to LU Decomposition<a class="headerlink" href="#ii-introduction-to-lu-decomposition" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="iii-lu-decomposition-doolittle-algorithm">
<h2>III. LU Decomposition Doolittle Algorithm<a class="headerlink" href="#iii-lu-decomposition-doolittle-algorithm" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="iv-lu-decomposition-implementation">
<h2>IV. LU Decomposition Implementation<a class="headerlink" href="#iv-lu-decomposition-implementation" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="v-partial-pivoting">
<h2>V.  Partial Pivoting<a class="headerlink" href="#v-partial-pivoting" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.linalg</span> <span class="k">as</span> <span class="nn">sl</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="learning-objectives">
<h2>Learning objectives:<a class="headerlink" href="#learning-objectives" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>More on direct methods: LU decomposition</p></li>
<li><p>Doolittle’s algorithm</p></li>
<li><p>Properties of lower-triangular matrices</p></li>
<li><p>Partial pivoting</p></li>
</ul>
</div>
<div class="section" id="id1">
<h2>I.   What are Matrices?<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>Now that you have gained a bit of understanding about Matrix, it is important to think, for once, what exactly are matrices, determinantsm singularity and solvability of systems. And also, the various operations that Python has for Matrix.</p>
<p>First things first, a bad thing with highschool mathematics is that it always makes matrices appear as something unrelated to the other fields of mathematics. But as you might have seen in the previous lectures, matrices can be used to solve systems of linear equations. Matrices have another bunch of <span style="badpun">useful uses</span> in mathematics, as you might recall from Remote Sensing and GIS for image manipulations etc. You should therefore think of matrices as another tool we use in Mathematics, and a tool in mathematics that has been passed to the hands of other scientists who applied to all kinds of important scientific magic.</p>
<p>Second, you should think of Matrices of something like a storage device, and stores values inside. Take our system of linear equations. Think about a poor chap, who before, the age of computers, had to solve everything by the power of hand and mind. Imagine given a system of linear equations for you to solve, and well, to solve this system of linear equations, the poor chap has to write <span class="math notranslate nohighlight">\(x,y,z\)</span> again and again and again, just like all of you might have done in highschool. It’s rather inconvenient, bothersome, wastes lots of paper and ink. What you need to solve any system of these linear equations, i.e. find the value of the unknowns, are the coefficients and the result of each system of linear equation on the RHS, and therefore, they thought, is there a way to write the coefficients, variables, and the results seprately, so that you don’t have to repeatedly write stuff again and again?</p>
<p>Well here comes matrices！Matrix <span class="math notranslate nohighlight">\(\pmb{A}\)</span> stores the coefficients, <span class="math notranslate nohighlight">\(\pmb{x}\)</span> stores the variables and <span class="math notranslate nohighlight">\(\pmb{b}\)</span> stores the results of the linear equations!</p>
<div class="math notranslate nohighlight">
\[\pmb{Ax =b }\]</div>
<p>You have already seent the capabilities of Gaussian elimination in solving equations. Now, when there are only 2 equations with 2 unknowns, Gaussian elimination is probably not the best method for solvng it. Rather, some of you should be able to solve these but inspection alone. But what happens when you have dozens of variables and dozens of unknowns, can you still solve it simply through inspection? Maybe some of you can, but I know that I cannot. The capabilities of matrices really shine when you have large complicated problems and it becomes difficult to keep track.</p>
<p>Imagine a system with dozens of equation and dozens of unknown, and let’s say that there exist a unique solution to our problem. Now, think about how times you would have to write <span class="math notranslate nohighlight">\(x,y,z\)</span>, if you well, did not have matrices, in order to solve the equation at hand. Basically, when solving these large equations, matrices make your life easier by decreasing the amount of things that you need to write.</p>
<p>Moreover, think about your computer, which is neither omniscent and omnipotent, and sometimes confused at the simplest of things. While your Python today can easily deal with symbols through your Sympy libary, and can even solve system of linear equations quite easily, think about the first computers that were invented, with, well, very limited processing power and memory. For example, one of the earliest computers, ENIAC, whose first program was to study the feasibility of thermonuclear weapons. ENIAC had to do a lot of mathematical calculations, while having very limited memory to play with, thus requiring some way of organizing the information used for these mathematical calculations in such a way that it would take less memory. So, MATRIX.</p>
<p>Even today, with Moore’s Law having continued for so many years, we are still in a continous arms race between computational power and the problems we are seeking to solve. While the amount of memory you could equip a computer with has increased significantly since ENIAC, so has the power hungriness of the problems we seek to solve. Just look at the list of supercomputers in the world, would the government waste so much of the taxpayer’s money on computational power they do not need? Thus, while we can increase memory, we should also try to make our methodology more memory efficient, so that they could solve really complex problem while armed with very limited memory. Making the problems we have into Matrices is a great way for saving lots of memory and computational power!</p>
<p>Last lecture we introduced the calculation for determinants, but how do determinants determine if an equation is solvable or not?</p>
<p>Let’s start with the determinant’s definition. From wikipedia, In linear algebra, the determinant is a scalar value that can be computed from the elements of a square matrix and encodes certain properties of the linear transformation described by the matrix. One of the most important properties that the determinant encodes is the solvability, meaning that finding the determinant can help us determine if the equaiton is solvable or not.</p>
<p>Then, let’s discuss solvability. When we try to solve an equation, we need information about the unknowns. If we are given enough information, the equation can be solved. If we are given too much information, or too little information, thus onverconstraining or underconstraining the problem, then the equation cannot be solved. You would encounter this especially when attempting to solve ODEs and PDEs in real world settings. Knowing how computationally expensive is to solve large scale problem, it is very important to know if the problem can be solved before beginning to solve the problem. Some of the most important topics in mathematics are about proving the solvability of certain forms or types of problems.</p>
<p>Ok, so let’s take a system of 2 linear equations, with 2 unknowns. If we make a graph, there could be 3 situations. The lines of the linear equation could intersect, the lines of the linear equations could not intersect,i.e. parallel or the two lines could simply be actually the same line in disguise, i.e. the line is still parallel, since a line is always parallel to itself, giving us infinitely many solutions. What we seek is the situation where the two lines intersect, and gives us a point, i.e. a unique solution, or the lines are not parallel.</p>
<p>We could write our equation in general form as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
ax + by = e \\
cx + dy = f
\end{split}\]</div>
<p>If we wrote our equation in matrix form it would be</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{pmatrix}
a &amp; b  \\
c &amp; d \\
\end{pmatrix}
\begin{pmatrix}
x  \\
y \\
\end{pmatrix}
=
\begin{pmatrix}
e  \\
f \\
\end{pmatrix}
\end{split}\]</div>
<p>We know the determinant for the matrix form above is</p>
<div class="math notranslate nohighlight">
\[
\pmb{det} = ad - bc
\]</div>
<p>Let’s write the equation instead in slope - intercept form</p>
<div class="math notranslate nohighlight">
\[\begin{split}
y = - \frac{a}{b} x + \frac{e}{b} \\
y = - \frac{c}{d} x + \frac{f}{d}
\end{split}\]</div>
<p>We know that there is unique solution when the lines are not parallel, and there is not a unique solution if the lines are not parallel. A line is parallel if the slope are equal, and not parallel if the slopes are not equal. We find the slopes as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
m_1 = - \frac{a}{b}\\
m_2 = - \frac{c}{d}
\end{split}\]</div>
<p>Let’s consider the case when the lines are parallel, i.e. slopes are equal and let’s manipulate it a little</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
- \frac{a}{b} = - \frac{c}{d} \\
ad - bc = 0
\end{split}\]</div>
<p>Let’s consider the case when the lines are not parallel, i.e. slopes are not equal and let’s manipulate it a little</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
- \frac{a}{b} \neq - \frac{c}{d} \\
ad - bc \neq 0
\end{split}\]</div>
<p>Hmmm, the <span class="math notranslate nohighlight">\(ad - bc\)</span> looks oddly familiar, what could it be?</p>
<p>Speaking about methodology improvement, we should also try to improve the algorithms we used. For example, is there some better algorithm than Gaussian elimination for solving linear equations?</p>
</div>
<div class="section" id="introduction-to-lu-decomposition">
<h2>Introduction to LU Decomposition<a class="headerlink" href="#introduction-to-lu-decomposition" title="Permalink to this headline">¶</a></h2>
<p>Last week we developed and implemented the Gaussian elimination method to solve the linear matrix system (<span class="math notranslate nohighlight">\(A\pmb{x}=\pmb{b}\)</span>).</p>
<p>This week we will consider a closely related solution method: <em>LU decomposition</em> or <em>LU factorisation</em>.</p>
<p>Both are examples of <em>direct</em> solution methods - in the next lecture we will consider the alternate approach to solve linear systems, namely <em>iterative</em> or <em>indirect</em> methods.</p>
</div>
<div class="section" id="lu-decomposition-motivation">
<h2>LU decomposition - motivation<a class="headerlink" href="#lu-decomposition-motivation" title="Permalink to this headline">¶</a></h2>
<p>Last week we implemented Gaussian elimination to solve the matrix system with <em>one</em> RHS vector <span class="math notranslate nohighlight">\(\pmb{b}\)</span>.</p>
<p>We often have to deal with problems where we have multiple RHS vectors, all with the same matrix <span class="math notranslate nohighlight">\(A\)</span>.</p>
<p>We could call the same code (e.g. our ‘upper_triangle’ and ‘back_substitution’ codes from last lecture) multiple times to solve all of these corresponding linear systems, but note that as the elimination algorithm is actually performing operations based upon (the same) <span class="math notranslate nohighlight">\(A\)</span> each time, we would actually be wasting time repeating exactly the same operations - this is therefore clearly not an efficient solution to this problem.</p>
<p>We could easily generalise our Gaussian elimination/back substitution algorithms to include multiple RHS column vectors in the augmented system, perform the same sequence of row operations (but now only once) to transform the matrix to upper-triangular form, and then perform back substitution on each of the transformed RHS vectors from the augmented system - cf. the use of Gaussian elimination to compute the inverse to a matrix by placing the identity on the right of the augmented system.</p>
<p>However, it is often the case that each RHS vector depends on the solutions to the matrix systems obtained from some or all of the earlier RHS vectors, and so this generalisation would not work in this case. For example, our discrete system could be of the form</p>
<div class="math notranslate nohighlight">
\[A\pmb{x}^{n+1} = \pmb{b}(\pmb{x}^n, \ldots)\]</div>
<p>where <span class="math notranslate nohighlight">\(\pmb{x}^{n+1}\)</span> is the numerical solution of a (ordinary or partial) differential equation at time level <span class="math notranslate nohighlight">\(n+1\)</span>, the RHS is a function of the the solution at the previous time level <span class="math notranslate nohighlight">\(n\)</span> (and possibly other things such as focing terms, represented by the <span class="math notranslate nohighlight">\(\ldots\)</span> above. <span class="math notranslate nohighlight">\(A\)</span> is then a discretisation of the differential equation written in the form that it maps the old solution to the new one. Time stepping this problem invovles solving the same linear system multiple times with different RHSs.</p>
<p>[NB. this is true if our model is <em>linear</em>, in the nonlinear case <span class="math notranslate nohighlight">\(A\)</span> would be updated evey time step].</p>
<p>Ok, so Gaussian elimination is nice, but way too inefficient, and basically, maybe we could do better?</p>
</div>
<div class="section" id="lu-decomposition-theory">
<h2>LU decomposition - theory<a class="headerlink" href="#lu-decomposition-theory" title="Permalink to this headline">¶</a></h2>
<p>To deal with this situation efficiently we <em>decompose</em> or <em>factorise</em> the matrix <span class="math notranslate nohighlight">\(A\)</span> in such a way that it is cheap to compute a new solution vector <span class="math notranslate nohighlight">\(\pmb{x}\)</span> for any given RHS vector <span class="math notranslate nohighlight">\(\pmb{b}\)</span>.  This decomposition involves a lower- and an upper-triangular matrix, hence the name LU decomposition. These matrices essentially <em>encode</em> the steps conducted in Gaussian elimination, so we don’t have to explicilty conduct all of the operations again and again.</p>
<p>Basically, we assume (well, there is actual rigorous mathematical proof that this can almost always be done) that our matrix <strong>A</strong> can be expressed as the matrix multiplication result of 2 other matrices, one in the upper triangle form, represented by the letter <strong>U</strong> and the other one in the lower triangle form, represented by the letter <strong>L</strong>. Since <strong>U</strong> is a upper triangle matrix, all entries below the diagonal are <span class="math notranslate nohighlight">\(0\)</span>, and for <strong>L</strong>, which is a lower triangle matrix, all entries above the diagonal are <span class="math notranslate nohighlight">\(0\)</span>.</p>
<p>Mathematically, let’s assume that we have already found/constructed a lower-triangular matrix (<span class="math notranslate nohighlight">\(L\)</span> - where all entries above the diagonal are zero) and an upper-triangular matrix (<span class="math notranslate nohighlight">\(U\)</span> - where all entries below the diagonal are zero) such that we can write</p>
<div class="math notranslate nohighlight">
\[ A = LU \]</div>
<p>To prove this, let’s say that</p>
<p>In this case the matrix system we need to solve for <span class="math notranslate nohighlight">\(\pmb{x}\)</span> becomes</p>
<div class="math notranslate nohighlight">
\[ A\pmb{x} = \pmb{b} \iff (LU)\pmb{x} = L(U\pmb{x}) = \pmb{b} \]</div>
<p>Notice that the matrix-vector product <span class="math notranslate nohighlight">\(U\pmb{x}\)</span> is itself a vector, let’s call it <span class="math notranslate nohighlight">\(\pmb{c}\)</span> for the time-being (i.e.
<span class="math notranslate nohighlight">\(\pmb{c}=U\pmb{x}\)</span>). Basically <span class="math notranslate nohighlight">\(U\pmb{x}\)</span> is a column like matrix. To illustrate</p>
<p>Let’s take a 3 by 3 matrix for example for <span class="math notranslate nohighlight">\(U\)</span> and <span class="math notranslate nohighlight">\(x\)</span> will correspndingly store 3 variables.</p>
<p>We can generalize a 3 by 3 <span class="math notranslate nohighlight">\(U\)</span> as below, with <span class="math notranslate nohighlight">\(a,b,c,d,e,f\)</span> being arbitrary constants, remebering that <span class="math notranslate nohighlight">\(U\)</span> is a upper triangle matrix, so all values below the diagonal are zero</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation*}
U = 
\begin{pmatrix}
a &amp; b &amp; c \\
0 &amp; d &amp; e \\
0 &amp; 0 &amp; f
\end{pmatrix}
\end{equation*}
\end{split}\]</div>
<p>We also have our matrix <span class="math notranslate nohighlight">\(x\)</span> where we store the variable (Yeah, I know it’s hard getting used to <span class="math notranslate nohighlight">\(x\)</span> as a matrix to store variables. If you are annoyed by the confusion, you could always replace the name <span class="math notranslate nohighlight">\(x\)</span> with the name “Matrix for storing variables”)</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation*}
\pmb{x}_{a.k.aThe Matrix for Storing the Variables} = 
\begin{pmatrix}
x \\
y \\
z
\end{pmatrix}
\end{equation*}
\end{split}\]</div>
<p>Then, if we do <span class="math notranslate nohighlight">\(Ux\)</span>, we get</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation*}
\pmb{Ux} = 
\begin{pmatrix}
a &amp; b &amp; c \\
0 &amp; d &amp; e \\
0 &amp; 0 &amp; f
\end{pmatrix}
\begin{pmatrix}
x \\
y  \\
z  
\end{pmatrix}
=
\begin{pmatrix}
ax + by + cz \\
0x + dy + ez  \\
0z + 0y + fz  
\end{pmatrix}
\end{equation*}
\end{split}\]</div>
<p>We understand that <span class="math notranslate nohighlight">\(\pmb{Ux}\)</span> is a column matrix, a.k.a a vector matrix, a.k.a a vector, which has 3 rows and 1 column.</p>
<p>The above system then reads</p>
<div class="math notranslate nohighlight">
\[ L\pmb{c} = \pmb{b} \]</div>
<p>where <span class="math notranslate nohighlight">\(L\)</span> is a matrix and <span class="math notranslate nohighlight">\(\pmb{c}\)</span> is an unknown.</p>
<p><span style="color:red">Note: The <span class="math notranslate nohighlight">\(L\)</span> and <span class="math notranslate nohighlight">\(U\)</span> here are not same as the one in the previous lecture in Gaussian elimination. </span></p>
<p>Previous Lecture
<span class="math notranslate nohighlight">\($
\pmb{Upper Triangle Form_{Gaussian} x = B} 
$\)</span></p>
<p>This Lecture
<span class="math notranslate nohighlight">\($
\pmb{LU x = B} 
$\)</span></p>
<p><span style="color:red">Note: The <span class="math notranslate nohighlight">\(L\)</span> and <span class="math notranslate nohighlight">\(U\)</span> here are not same as the one in the previous lecture in Gaussian elimination. </span></p>
<p>As <span class="math notranslate nohighlight">\(L\)</span> is in lower-triangular form we can use forward substitution (generalising the back subsitution algorithm/code we developed last week) to very easily find <span class="math notranslate nohighlight">\(\pmb{c}\)</span> in relatively few operations (we don’t need to call the entire Gaussian elimination algorithm).</p>
<p>Once we know <span class="math notranslate nohighlight">\(\pmb{c}\)</span> we then solve the second linear system</p>
<div class="math notranslate nohighlight">
\[ U\pmb{x} = \pmb{c} \]</div>
<p>where now we can use the fact that <span class="math notranslate nohighlight">\(U\)</span> is upper-triangular to use our back substitution algorithm again very efficiently to give the solution <span class="math notranslate nohighlight">\(\pmb{x}\)</span> we require.</p>
<p>So for a given <span class="math notranslate nohighlight">\(\pmb{b}\)</span> we can find the corresponding <span class="math notranslate nohighlight">\(\pmb{x}\)</span> very efficiently, we can therefore do this repeatedly as each new <span class="math notranslate nohighlight">\(\pmb{b}\)</span> is given to us.</p>
<p>Our challenge is therefore to find the matrices <span class="math notranslate nohighlight">\(L\)</span> and <span class="math notranslate nohighlight">\(U\)</span> allowing us to perform the decomposition <span class="math notranslate nohighlight">\(A=LU\)</span>.</p>
<ol class="simple">
<li><p>We assume that we have already found <span class="math notranslate nohighlight">\(\pmb{L}\)</span> and <span class="math notranslate nohighlight">\(\pmb{U}\)</span>. Our objective is to find <span class="math notranslate nohighlight">\(\pmb{x}\)</span>, i.e. we aim to find the unknowns stored in <span class="math notranslate nohighlight">\(\pmb{x}\)</span> which we will find by finding <span class="math notranslate nohighlight">\(\pmb{x}\)</span> We begin with the matrix form</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\pmb{Ax =b}
\]</div>
<ol class="simple">
<li><p>Since we know that <span class="math notranslate nohighlight">\(\pmb{A = LU}\)</span>, we can write</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\pmb{LUx = b}
\]</div>
<ol class="simple">
<li><p>We know that <span class="math notranslate nohighlight">\(\pmb{Ux}\)</span> is a column vector, and we can set a column vector <span class="math notranslate nohighlight">\(\pmb{c}\)</span> and make it <span class="math notranslate nohighlight">\(\pmb{c =Ux}\)</span>, thus we write</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
\pmb{Lc = b}
\]</div>
<ol class="simple">
<li><p>Since we know <span class="math notranslate nohighlight">\(\pmb{L}\)</span>, we will see how we find <span class="math notranslate nohighlight">\(\pmb{L}\)</span> and <span class="math notranslate nohighlight">\(\pmb{U}\)</span> later, we know that <span class="math notranslate nohighlight">\(\pmb{L}\)</span> is applied to column matrix and results in another column matrix, thus we can use back substitution to very easily find <span class="math notranslate nohighlight">\(\pmb{c}\)</span></p></li>
<li><p>Once we have found <span class="math notranslate nohighlight">\(\pmb{c}\)</span>, since we have <span class="math notranslate nohighlight">\(\pmb{U}\)</span>, and we know that <span class="math notranslate nohighlight">\(\pmb{x}\)</span> is also a vector, then, using backward substitution again, we can easily find <span class="math notranslate nohighlight">\(\pmb{x}\)</span></p></li>
</ol>
</div>
<div class="section" id="lu-decomposition-doolittle-algorithm">
<h2>LU Decomposition Doolittle Algorithm<a class="headerlink" href="#lu-decomposition-doolittle-algorithm" title="Permalink to this headline">¶</a></h2>
<p>Recall the comment above on the <span class="math notranslate nohighlight">\(L\)</span> and <span class="math notranslate nohighlight">\(U\)</span> matrices encoding the steps taken in Gaussian elimination.  Let’s see how this works through the development of the so-called <em>Doolittle algorithm</em>.</p>
<p>Let’s consider an example matrix:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  A=\begin{bmatrix}
    {\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\\
{\color{black}5} &amp; {\color{black}14} &amp; {\color{black}7} &amp; {\color{black}10}\\
{\color{black}20} &amp; {\color{black}77} &amp; {\color{black}41} &amp; {\color{black}48}\\
{\color{black}25} &amp; {\color{black}91} &amp; {\color{black}55} &amp; {\color{black}67}\\
    \end{bmatrix}
\end{split}\]</div>
<p>the first step of Gaussian elimination is to set the
sub-diagonal elements in the first column to zero by subtracting multiples of
the first row from each of the subsequent rows.</p>
<p>For this example, using the symbolic notiation from last week
this requires the row operations</p>
<p>\begin{align}
Eq. (2) &amp;\leftarrow Eq. (2) - 1\times Eq. (1)\
Eq. (3) &amp;\leftarrow Eq. (3) - 4\times Eq. (1)\
Eq. (4) &amp;\leftarrow Eq. (4) - 5\times Eq. (1)\
\end{align}</p>
<p>or mathematically, and for each element of the matrix (remembering that we are adding rows together - while one of
the entries of a row will end up being zero, this also has the consequence of updating the rest of the values in that row, hence the iteration over <span class="math notranslate nohighlight">\(j\)</span> below):</p>
<p>\begin{align}
A_{2j} &amp;\leftarrow A_{2j} - \frac{A_{21}}{A_{11}} A_{1j} = A_{2j} - \frac{5}{5} \times A_{1j}, \quad j=1,2,3,4\
A_{3j} &amp;\leftarrow A_{3j} - \frac{A_{31}}{A_{11}} A_{1j} = A_{3j} - \frac{20}{5} \times A_{1j}, \quad j=1,2,3,4\
A_{4j} &amp;\leftarrow A_{4j} - \frac{A_{41}}{A_{11}} A_{1j} = A_{4j} - \frac{25}{5} \times A_{1j}, \quad j=1,2,3,4\
\end{align}</p>
<p>Notice that we can also write these exact operations on elements in terms of multiplication by a carefully chosen lower-triangular matrix where the non-zero’s below the diagonal are restricted to a single column, e.g. for the example above</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \begin{bmatrix}
    {\color{black}1} &amp; {\color{black}0} &amp; {\color{black}0} &amp; {\color{black}0}\\
    {\color{Orange}{-1}} &amp; {\color{black}1} &amp; {\color{black}0} &amp; {\color{black}0}\\
    {\color{Orange}{-4}} &amp; {\color{black}0} &amp; {\color{black}1} &amp; {\color{black}0}\\
    {\color{Orange}{-5}} &amp; {\color{black}0} &amp; {\color{black}0} &amp; {\color{black}1}\\   
  \end{bmatrix}\qquad\times\qquad\begin{bmatrix}
    {\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\\
    {\color{black}5} &amp; {\color{black}14} &amp; {\color{black}7} &amp; {\color{black}10}\\
    {\color{black}20} &amp; {\color{black}77} &amp; {\color{black}41} &amp; {\color{black}48}\\
    {\color{black}25} &amp; {\color{black}91} &amp; {\color{black}55} &amp; {\color{black}67}\\   
  \end{bmatrix}\qquad=\qquad\begin{bmatrix}
    {\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\\
    {\color{blue}{0}} &amp; {\color{blue}{7}} &amp; {\color{blue}{2}} &amp; {\color{blue}{1}}\\
    {\color{blue}{0}} &amp; {\color{blue}{49}} &amp; {\color{blue}{21}} &amp; {\color{blue}{12}}\\
    {\color{blue}{0}} &amp; {\color{blue}{56}} &amp; {\color{blue}{30}} &amp; {\color{blue}{22}}\\    
  \end{bmatrix}
\end{split}\]</div>
<p>The lower-triangular matrix (let’s call this one <span class="math notranslate nohighlight">\(L_0\)</span>) is thus encoding the first step in Gaussian elimination.</p>
<p>The next step involves taking the second row of the updated matrix as the new pivot (we will ignore partial pivoting for simplicity), and subtracting multiples of this row from those below in order to set the zeros below the diagonal in the second column to zero.</p>
<p>Note that thios step can be achieved here with the multiplication by the following lower-triangular matrix (call this one <span class="math notranslate nohighlight">\(L_1\)</span>)</p>
<p>\begin{equation*}
\begin{bmatrix}
{\color{black}1} &amp; {\color{black}0} &amp; {\color{black}0} &amp; {\color{black}0}\
{\color{black}0} &amp; {\color{black}1} &amp; {\color{black}0} &amp; {\color{black}0}\
{\color{black}0} &amp; {\color{Orange}{-7}} &amp; {\color{black}1} &amp; {\color{black}0}\
{\color{black}0} &amp; {\color{Orange}{-8}} &amp; {\color{black}0} &amp; {\color{black}1}\
\end{bmatrix}\qquad\times\qquad\begin{bmatrix}
{\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\
{\color{black}0} &amp; {\color{black}7} &amp; {\color{black}2} &amp; {\color{black}1}\
{\color{black}0} &amp; {\color{black}49} &amp; {\color{black}21} &amp; {\color{black}12}\
{\color{black}0} &amp; {\color{black}56} &amp; {\color{black}30} &amp; {\color{black}22}\
\end{bmatrix}\qquad=\qquad\begin{bmatrix}
{\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\
{\color{black}0} &amp; {\color{black}7} &amp; {\color{black}2} &amp; {\color{black}1}\
{\color{black}0} &amp; {\color{blue}{0}} &amp; {\color{blue}{7}} &amp; {\color{blue}{5}}\
{\color{black}0} &amp; {\color{blue}{0}} &amp; {\color{blue}{14}} &amp; {\color{blue}{14}}\
\end{bmatrix}
\end{equation*}</p>
<p>and finally for this example to get rid the of the leading 14 on the final row:</p>
<p>\begin{equation*}
\begin{bmatrix}
{\color{black}1} &amp; {\color{black}0} &amp; {\color{black}0} &amp; {\color{black}0}\
{\color{black}0} &amp; {\color{black}1} &amp; {\color{black}0} &amp; {\color{black}0}\
{\color{black}0} &amp; {\color{black}0} &amp; {\color{black}1} &amp; {\color{black}0}\
{\color{black}0} &amp; {\color{black}0} &amp; {\color{Orange}{-2}} &amp; {\color{black}{1}}\
\end{bmatrix}\qquad\times\qquad\begin{bmatrix}
{\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\
{\color{black}0} &amp; {\color{black}7} &amp; {\color{black}2} &amp; {\color{black}1}\
{\color{black}0} &amp; {\color{black}0} &amp; {\color{black}7} &amp; {\color{black}5}\
{\color{black}0} &amp; {\color{black}0} &amp; {\color{black}14} &amp; {\color{black}14}\
\end{bmatrix}\qquad=\qquad\begin{bmatrix}
{\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\
{\color{black}0} &amp; {\color{black}7} &amp; {\color{black}2} &amp; {\color{black}1}\
{\color{black}0} &amp; {\color{black}0} &amp; {\color{black}7} &amp; {\color{black}5}\
{\color{black}0} &amp; {\color{black}0} &amp; {\color{blue}{0}} &amp; {\color{blue}{4}}\
\end{bmatrix}
\end{equation*}</p>
<p>where this lower triangular matrix we will call <span class="math notranslate nohighlight">\(L_2\)</span>, and the RHS matrix is now in upper-triangular form as we expect from Gaussian elimination (call this <span class="math notranslate nohighlight">\(U\)</span>).</p>
<p>In summary, the above operations (starting from <span class="math notranslate nohighlight">\(A\)</span>, first multipling pn the left by <span class="math notranslate nohighlight">\(L_0\)</span>, the multiplying the result on the left by <span class="math notranslate nohighlight">\(L_1\)</span> and so on to arrive at an upper trianglualr matrix <span class="math notranslate nohighlight">\(U\)</span>) can be written as</p>
<div class="math notranslate nohighlight">
\[ L_2(L_1(L_0A)) = U \]</div>
<p><span style="color:red"> Note that these special lower-triangular matrices <span class="math notranslate nohighlight">\(L_0, \ldots\)</span> are all examples of what is known as <em>atomic</em> lower-triangular matrices: a special form of unitriangular matrix - the diagonals are unity, where the off-diagonal entries are all zero apart from in a single column. </span></p>
<p><span style="color:red">Notice that for these special, simple matrices, their inverse is simply the original with the sign of those off-diagnonals changed:</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[
  \begin{array}{rrrrrrrrr}
    1      &amp; 0      &amp; \cdots      &amp;        &amp;              &amp;        &amp;         &amp;   &amp; 0 \\
    0      &amp; 1      &amp; 0           &amp; \cdots &amp;              &amp;        &amp;         &amp;   &amp; 0 \\
    0      &amp; \ddots &amp; \ddots      &amp; \ddots &amp;              &amp;        &amp;         &amp;   &amp;  \vdots \\
    \vdots &amp; \ddots &amp; \ddots      &amp; \ddots &amp;              &amp;        &amp;         &amp;   &amp;  \\
           &amp;        &amp;             &amp;   0    &amp;   1          &amp;  0     &amp;         &amp; &amp;  &amp;  \\           
           &amp;        &amp;             &amp;   0    &amp;   l_{i+1,i}  &amp;  1     &amp;  \ddots &amp;   &amp;  &amp;  \\  
           &amp;        &amp;             &amp;   0    &amp;   l_{i+2,i}  &amp;  0     &amp;  \ddots &amp;   &amp; &amp;  \\  
           &amp;        &amp;             &amp; \vdots &amp;   \vdots     &amp; \vdots &amp;  \ddots &amp;   &amp; 0 &amp;  \\               
    0      &amp; \cdots &amp;             &amp; 0      &amp;   l_{n,i}    &amp; 0      &amp;  \cdots &amp; 0 &amp; 1 &amp;  \\    
\end{array}
\right]^{-1}
=
\left[
  \begin{array}{rrrrrrrrr}
    1      &amp; 0      &amp; \cdots      &amp;        &amp;              &amp;        &amp;         &amp;   &amp; 0 \\
    0      &amp; 1      &amp; 0           &amp; \cdots &amp;              &amp;        &amp;         &amp;   &amp; 0 \\
    0      &amp; \ddots &amp; \ddots      &amp; \ddots &amp;              &amp;        &amp;         &amp;   &amp;  \vdots \\
    \vdots &amp; \ddots &amp; \ddots      &amp; \ddots &amp;              &amp;        &amp;         &amp;   &amp;  \\
           &amp;        &amp;             &amp;   0    &amp;   1          &amp;  0     &amp;         &amp; &amp;  &amp;  \\           
           &amp;        &amp;             &amp;   0    &amp;   -l_{i+1,i}  &amp;  1     &amp;  \ddots &amp;   &amp;  &amp;  \\  
           &amp;        &amp;             &amp;   0    &amp;   -l_{i+2,i}  &amp;  0     &amp;  \ddots &amp;   &amp; &amp;  \\  
           &amp;        &amp;             &amp; \vdots &amp;   \vdots     &amp; \vdots &amp;  \ddots &amp;   &amp; 0 &amp;  \\               
    0      &amp; \cdots &amp;             &amp; 0      &amp;   -l_{n,i}    &amp; 0      &amp;  \cdots &amp; 0 &amp; 1 &amp;  \\    
\end{array}
\right]
\end{split}\]</div>
<div class="section" id="span-style-color-blue-exercise-6-1-lower-triangular-matrices-span">
<h3><span style="color:blue">Exercise 6.1: lower-triangular matrices</span><a class="headerlink" href="#span-style-color-blue-exercise-6-1-lower-triangular-matrices-span" title="Permalink to this headline">¶</a></h3>
<p>Convince yourselves of the following facts:</p>
<ul class="simple">
<li><p>The above statement on what the inverse of the special <span class="math notranslate nohighlight">\(L\)</span> matrices is - check on a small example.</p></li>
<li><p>The multiplication of arbitrary lower-triangular square matrices is also lower-triangular.</p></li>
<li><p><span class="math notranslate nohighlight">\(L_2(L_1(L_0A)) = U \implies A = L_0^{-1}(L_1^{-1}(L_2^{-1}U))\)</span></p></li>
<li><p>and hence that <span class="math notranslate nohighlight">\(A=LU\)</span> where <span class="math notranslate nohighlight">\(U\)</span> is the upper-triangular matrix found at the end of Guassian elimination, and where <span class="math notranslate nohighlight">\(L\)</span> is the
following  matrix
<span class="math notranslate nohighlight">\($ L = L_0^{-1}L_1^{-1}L_2^{-1} $\)</span></p></li>
<li><p>Finally, compute this product of these lower-triangular matrices to show that
<span class="math notranslate nohighlight">\($L = 
\begin{bmatrix}
  {\color{black}1} &amp; {\color{black}0} &amp; {\color{black}0} &amp; {\color{black}0}\\
  {\color{black}{1}} &amp; {\color{black}1} &amp; {\color{black}0} &amp; {\color{black}0}\\
  {\color{black}{4}} &amp; {\color{black}7} &amp; {\color{black}1} &amp; {\color{black}0}\\
  {\color{black}{5}} &amp; {\color{black}8} &amp; {\color{black}2} &amp; {\color{black}1}\\   
\end{bmatrix}
$\)</span>
i.e. that the multiplication of these individual atomic matrices (importantly in this order) simply merges the entries from the non-zero columns of each atomic matrix, and hence is both lower-triangular, as well as trivial to compute.</p></li>
</ul>
<p><span style="color:red"> So now, by this slide, we have found <span class="math notranslate nohighlight">\(\pmb{L}\)</span>, Hooray!  </span></p>
</div>
</div>
<div class="section" id="lu-decomposition-implementation">
<h2>LU Decomposition Implementation<a class="headerlink" href="#lu-decomposition-implementation" title="Permalink to this headline">¶</a></h2>
<p>So we can build an LU code easily from our Gaussian elimination code from last lecture which already works out and performs these tasks.</p>
<p>The final <span class="math notranslate nohighlight">\(U\)</span> matrix we need here is as was already constructed through Gaussian elimination, the entries of <span class="math notranslate nohighlight">\(L\)</span> we need are simply the <span class="math notranslate nohighlight">\({A_{ik}}/{A_{kk}}\)</span> multipliers we computed as part of the elimination, but threw away previously.</p>
<p>For a given pivot row <span class="math notranslate nohighlight">\(k\)</span>, for each of these multipliers (for every row below the pivot), as we compute them we know that we are going to transform the augmented matrix in order to achieve a new zero below the diagonal - we can store each multiplier in this position before moving on to the following row, we implicitly know that the diagonals of <span class="math notranslate nohighlight">\(L\)</span> will be unity and so don’t need to store these (and noting that we don’t actually have a space for them anyway!). We then move on to the following pivot row, replacing the zeros in the corresponding column we are zero’ing, but again using the now spare space to store the multipliers.</p>
<p>For example, for the case above</p>
<div class="math notranslate nohighlight">
\[\begin{split} A = 
  \begin{bmatrix}
    {\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\\
    {\color{black}5} &amp; {\color{black}14} &amp; {\color{black}7} &amp; {\color{black}10}\\
    {\color{black}20} &amp; {\color{black}77} &amp; {\color{black}41} &amp; {\color{black}48}\\
    {\color{black}25} &amp; {\color{black}91} &amp; {\color{black}55} &amp; {\color{black}67}\\   
  \end{bmatrix}\quad\rightarrow\quad
  \begin{bmatrix}
    {\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\\
    {\color{blue}{1}} &amp; {\color{black}{14 - 1\times7}} &amp; {\color{black}{7-1\times5}} &amp; {\color{black}{10-1\times9}}\\
    {\color{blue}{4}} &amp; {\color{black}{77 - 4\times7}} &amp; {\color{black}{41-4\times5}} &amp; {\color{black}{48-4\times9}}\\
    {\color{blue}{5}} &amp; {\color{black}{91 - 5\times7}} &amp; {\color{black}{55-5\times5}} &amp; {\color{black}{67-5\times9}}\\ 
  \end{bmatrix}\quad\rightarrow\quad
  \begin{bmatrix}
    {\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\\
    {\color{blue}{1}} &amp; {\color{black}{7}} &amp; {\color{black}{2}} &amp; {\color{black}{1}}\\
    {\color{blue}{4}} &amp; {\color{black}{49}} &amp; {\color{black}{21}} &amp; {\color{black}{12}}\\
    {\color{blue}{5}} &amp; {\color{black}{56}} &amp; {\color{black}{30}} &amp; {\color{black}{22}}\\    
  \end{bmatrix}\quad\rightarrow\quad
  \begin{bmatrix}
    {\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\\
    {\color{blue}{1}} &amp; {\color{black}{7}} &amp; {\color{black}{2}} &amp; {\color{black}{1}}\\
    {\color{blue}{4}} &amp; {\color{blue}{7}} &amp; {\color{black}{21-2\times7}} &amp; {\color{black}{12-1\times7}}\\
    {\color{blue}{5}} &amp; {\color{blue}{8}} &amp; {\color{black}{30-2\times8}} &amp; {\color{black}{22-1\times8}}\\    
  \end{bmatrix}\quad\rightarrow\quad
  \begin{bmatrix}
    {\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\\
    {\color{blue}1} &amp; {\color{black}7} &amp; {\color{black}2} &amp; {\color{black}1}\\
    {\color{blue}4} &amp; {\color{blue}{7}} &amp; {\color{black}{7}} &amp; {\color{black}{5}}\\
    {\color{blue}5} &amp; {\color{blue}{8}} &amp; {\color{black}{14}} &amp; {\color{black}{14}}\\
  \end{bmatrix}\quad\rightarrow\quad
  \begin{bmatrix}
    {\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\\
    {\color{blue}1} &amp; {\color{black}7} &amp; {\color{black}2} &amp; {\color{black}1}\\
    {\color{blue}4} &amp; {\color{blue}{7}} &amp; {\color{black}{7}} &amp; {\color{black}{5}}\\
    {\color{blue}5} &amp; {\color{blue}{8}} &amp; {\color{blue}{2}} &amp; {\color{black}{14-2\times5}}\\
  \end{bmatrix}\quad\rightarrow\quad
  \begin{bmatrix}
    {\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\\
    {\color{blue}1} &amp; {\color{black}7} &amp; {\color{black}2} &amp; {\color{black}1}\\
    {\color{blue}4} &amp; {\color{blue}7} &amp; {\color{black}7} &amp; {\color{black}5}\\
    {\color{blue}5} &amp; {\color{blue}8} &amp; {\color{blue}{2}} &amp; {\color{black}{4}}\\
  \end{bmatrix}
  = [\color{blue}L\backslash U]
\end{split}\]</div>
<p>We find that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
U =
  \begin{bmatrix}
    {\color{black}5} &amp; {\color{black}7} &amp; {\color{black}5} &amp; {\color{black}9}\\
    {\color{black}0} &amp; {\color{black}7} &amp; {\color{black}2} &amp; {\color{black}1}\\
    {\color{black}0} &amp; {\color{black}0} &amp; {\color{black}7} &amp; {\color{black}5}\\
    {\color{black}0} &amp; {\color{black}0} &amp; {\color{black}0} &amp; {\color{black}{4}}\\
  \end{bmatrix}
\end{split}\]</div>
<div class="section" id="span-style-color-blue-exercise-6-2-lu-decomposition-span">
<h3><span style="color:blue">Exercise 6.2: LU decomposition</span><a class="headerlink" href="#span-style-color-blue-exercise-6-2-lu-decomposition-span" title="Permalink to this headline">¶</a></h3>
<p>Starting from your Gaussian elimination code produce a new code to compute the LU decomposition of a matrix. First, store <span class="math notranslate nohighlight">\(L\)</span> and <span class="math notranslate nohighlight">\(U\)</span> in two different matrices; you could then try a version where you store the entries of both <span class="math notranslate nohighlight">\(L\)</span> and <span class="math notranslate nohighlight">\(U\)</span> in <span class="math notranslate nohighlight">\(A\)</span> as described above.</p>
<p><span style="color:red"> So now, by this point, we have found <span class="math notranslate nohighlight">\(\pmb{U}\)</span>, Hooray!  </span></p>
<p><span style="color:red"> After finding both <span class="math notranslate nohighlight">\(\pmb{L}\)</span> and <span class="math notranslate nohighlight">\(\pmb{U}\)</span>, we could use our aforementioned method to solve equations!   </span></p>
</div>
</div>
<div class="section" id="id2">
<h2>V.  Partial Pivoting<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>At the end of last week we commented that a problem could occur in a numeical implementation of our algorithm if we had a situation where the <span class="math notranslate nohighlight">\(A_{kk}\)</span> we divide through by in the Gaussian elimination and/or back substitution algorithms might be zero (or close to zero).</p>
<p>Using Gaussian elimination as an example, let’s again consider the algorithm mid-way working on an arbitrary matrix system, i.e. assume that the first <span class="math notranslate nohighlight">\(k\)</span> rows have already been transformed into upper-triangular form, while the equations/rows below are not yet in this form:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\left[
  \begin{array}{rrrrrrr|r}
    A_{11} &amp; A_{12} &amp; A_{13} &amp; \cdots &amp; A_{1k}  &amp; \cdots &amp; A_{1n} &amp; b_1 \\
    0      &amp; A_{22} &amp; A_{23} &amp; \cdots &amp; A_{2k} &amp; \cdots &amp; A_{2n} &amp; b_2 \\
    0      &amp; 0      &amp; A_{33} &amp; \cdots &amp; A_{3k}  &amp; \cdots &amp; A_{3n} &amp; b_3 \\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots  &amp; \ddots &amp; \vdots &amp; \vdots \\
\hdashline    
    0      &amp; 0      &amp; 0      &amp; \cdots &amp; A_{kk}  &amp; \cdots &amp; A_{kn} &amp; b_k \\    
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots  &amp; \ddots &amp; \vdots &amp; \vdots \\
    0      &amp; 0      &amp; 0      &amp; \cdots &amp; A_{nk}  &amp; \cdots &amp; A_{nn} &amp; b_n \\
\end{array}
\right]
\end{split}\]</div>
<p>Note we have drawn the horizontal dashed line one row higher, as we are not going to blindly asssume that it is wise to take the current row <span class="math notranslate nohighlight">\(k\)</span> as the pivot row, and <span class="math notranslate nohighlight">\(A_{kk}\)</span> as the so-called pivot element.</p>
<p><em>Partial pivoting</em> selects the best pivot (row or element) as the one where the <span class="math notranslate nohighlight">\(A_{ik}\)</span> (for <span class="math notranslate nohighlight">\(i\ge k\)</span>) value is largest (relative to the other values of components in its own row <span class="math notranslate nohighlight">\(i\)</span>), and then swaps this row with the current <span class="math notranslate nohighlight">\(k\)</span> row.</p>
<p>To generalise our codes above we would simply need to search for this row, and perform the row swap operation.</p>
<p>Python’s <code class="docutils literal notranslate"><span class="pre">scipy.linalg</span></code> library has its own implementation of the LU decomposition, that uses partial pivoting.</p>
<p>Ok, so let’s illustrate partial pivoting with an example</p>
<p>Suppose that we have the matrix <span class="math notranslate nohighlight">\(\pmb{A}\)</span> from before</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
A = 
  \begin{bmatrix}
    5 &amp; 7 &amp; 5 &amp;  9 \\
    5 &amp; 14 &amp; 7 &amp; 10 \\
    20 &amp; 77 &amp;41 &amp; 48 \\
    25 &amp; 91 &amp; 55 &amp; 67 \\
  \end{bmatrix}
\end{split}\]</div>
<p>And then we do some timeskipping and skip to partway through</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
A = 
  \begin{bmatrix}
    5 &amp; 7 &amp; 5 &amp;  9 \\
    0 &amp; 7 &amp; 2 &amp; 1 \\
    0 &amp; 49 &amp;21 &amp; 12 \\
    0 &amp; 56 &amp; 30 &amp; 22 \\
  \end{bmatrix}
\end{split}\]</div>
<p>Now, magic happens for the sake of illustrating the Partial Pivoting
Magic magic poof poof and magically <span class="math notranslate nohighlight">\(7\)</span> becomes <span class="math notranslate nohighlight">\(0\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split} 
A = 
  \begin{bmatrix}
    5 &amp; 7 &amp; 5 &amp;  9 \\
    0 &amp; 0 &amp; 2 &amp; 1 \\
    0 &amp; 49 &amp;21 &amp; 12 \\
    0 &amp; 56 &amp; 30 &amp; 22 \\
  \end{bmatrix}
\end{split}\]</div>
<p>Suppose that the matrix storing our unknowns is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pmb{x} = 
\begin{bmatrix}
  x \\
  y \\
  z \\
  letter\;\;after\;\;z
\end{bmatrix}
\end{split}\]</div>
<p>And the matrix storing the results of our equations, after all of the Gaussian elimination previously that have modified the matrix <span class="math notranslate nohighlight">\(\pmb{b}\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pmb{b} = 
\begin{bmatrix}
  b_1 \\
  b_2 \\
  b_3 \\
  b_4 
\end{bmatrix}
\end{split}\]</div>
<p>Writing this in equation this would be</p>
<div class="math notranslate nohighlight">
\[\begin{split}
5x + 7y + 5z + 9(letter\;\;after\;\;z) = b_1 \\
0x + 0y + 2z + 1(letter\;\;after\;\;z) = b_2 \\
0x + 49y + 21z + 12(letter\;\;after\;\;z) = b_3  \\
0x + 56y + 30z + 22(letter\;\;after\;\;z) = b_4
\end{split}\]</div>
<p>Now, we are going to use equation 2 and equation 3</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
A = 
  \begin{bmatrix}
    5 &amp; 7 &amp; 5 &amp;  9 \\
    0 &amp; 0 &amp; 2 &amp; 1 \\
    0 &amp; 49 &amp;21 &amp; 12 \\
    0 &amp; 56 &amp; 30 &amp; 22 \\
  \end{bmatrix}
\end{split}\]</div>
<p>The coefficient of the second unknown in the second equation is 0. The coefficient of the second unknown in the third equation is 49. Thus, I will divide the coefficient of the 3rd equation with the coefficient of the 2nd equation, and then I would multiply the coefficient of the 3rd equation by the quotient. As such, I will divide <span class="math notranslate nohighlight">\(49/0\)</span>, and then, yup I will get an error since you cannot divide by <span class="math notranslate nohighlight">\(0\)</span>. It does not neccesarily have to be <span class="math notranslate nohighlight">\(0\)</span> to give errors, even if it is very close to <span class="math notranslate nohighlight">\(0\)</span>, it will still give an error.
Thus what can I do?</p>
<p>Well, I need two equations. I cannot use the equation 2 because there is a <span class="math notranslate nohighlight">\(0\)</span>. Then, I will use equation 3 and equation 4. Therefore, let’s swap the position of equation 4 and equation 2.</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
A = 
  \begin{bmatrix}
    5 &amp; 7 &amp; 5 &amp;  9 \\
    0 &amp; 56 &amp; 30 &amp; 22 \\
    0 &amp; 49 &amp;21 &amp; 12 \\
    0 &amp; 0 &amp; 2 &amp; 1 \\
  \end{bmatrix}
\end{split}\]</div>
<p><span style="color:red">Remember: when you swap rows in matrix <span class="math notranslate nohighlight">\(\pmb{A}\)</span>, you must also swap rows in the matrix <span class="math notranslate nohighlight">\(\pmb{b}\)</span>. Matrix <span class="math notranslate nohighlight">\(\pmb{x}\)</span> does not have to swapped since the order of the variables has not changed. </span></p>
<p>The matrix storing our unknowns remains</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pmb{x} = 
\begin{bmatrix}
  x \\
  y \\
  z \\
  letter\;\;after\;\;z
\end{bmatrix}
\end{split}\]</div>
<p>And the matrix storing the results of our equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\pmb{b} = 
\begin{bmatrix}
  b_1 \\
  b_4 \\
  b_3 \\
  b_2 
\end{bmatrix}
\end{split}\]</div>
<p>Writing this in equation this would be</p>
<div class="math notranslate nohighlight">
\[\begin{split}
5x + 7y + 5z + 9(letter\;\;after\;\;z) = b_1 \\
0x + 56y + 30z + 22(letter\;\;after\;\;z) = b_4 \\
0x + 49y + 21z + 12(letter\;\;after\;\;z) = b_3  \\
0x + 0y + 2z + 1(letter\;\;after\;\;z) = b_2 
\end{split}\]</div>
<p>Inspeacing this equation, we see that the equation is essentially the same as it was before the swap, so we can say that our action to swap it is a valid action. I have rewritten the equation before the swap as reference</p>
<div class="math notranslate nohighlight">
\[\begin{split}
5x + 7y + 5z + 9(letter\;\;after\;\;z) = b_1 \\
0x + 0y + 2z + 1(letter\;\;after\;\;z) = b_2 \\
0x + 49y + 21z + 12(letter\;\;after\;\;z) = b_3  \\
0x + 56y + 30z + 22(letter\;\;after\;\;z) = b_4
\end{split}\]</div>
<p>Now let’s continue, after we finished swapping, and we will focus only on getting to the upper triangle form, and only on matrix <span class="math notranslate nohighlight">\(\pmb{A}\)</span>. The matrix <span class="math notranslate nohighlight">\(\pmb{b}\)</span> will also change accordingly as detailed in the previous lecture, but let’s focus on matrix <span class="math notranslate nohighlight">\(\pmb{A}\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split} 
A = 
  \begin{bmatrix}
    5 &amp; 7 &amp; 5 &amp;  9 \\
    0 &amp; 56 &amp; 30 &amp; 22 \\
    0 &amp; 56 &amp; 24 &amp; 96/7 \\
    0 &amp; 0 &amp; 2 &amp; 1 \\
  \end{bmatrix}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split} 
A = 
  \begin{bmatrix}
    5 &amp; 7 &amp; 5 &amp;  9 \\
    0 &amp; 56 &amp; 30 &amp; 22 \\
    0 &amp; 0 &amp; -6 &amp; 96/7 -22 \\
    0 &amp; 0 &amp; 2 &amp; 1 \\
  \end{bmatrix}
\end{split}\]</div>
<p>We will not encounter the problem with dividing by zero anymore, at least for this matrix !</p>
<p>Note : this matrix was nice and only required one swap. But if your matrix has lots of <span class="math notranslate nohighlight">\(0\)</span> or very small numbers, then maybe you might need more swaps. You might also want to nondimensionalize that matrix! That is, of course assuming that the equations contain enough information to actually allow you to solve the equation. You could use the determinant, or the Gauss-Jordan in the previous lecture to check if there is actually a solution. You should always check the solvability of an equation before solving it, since trying to solve an equation which cannot be solved is wasted effort. <span class="personal experience"> You may spend days debugging your code and scratching your head as to what went wrong, when in fact, the equations you are solving may not even be able to give a solution, i.e. ill conditioned </span></p>
<p>Note: You could use conditionals to control the swapping or the skipping of rows. Although the example here used <span class="math notranslate nohighlight">\(0\)</span>, it could be a very small number too, and not neccesary <span class="math notranslate nohighlight">\(0\)</span> that could cause the problem, so maybe it would be nice to compare the conditional to a certain threshold to decided whether to swap or not.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span>   <span class="mf">5.</span><span class="p">,</span>  <span class="mf">9.</span><span class="p">],</span>
               <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">14.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">],</span>
               <span class="p">[</span><span class="mf">20.</span><span class="p">,</span> <span class="mf">77.</span><span class="p">,</span> <span class="mf">41.</span><span class="p">,</span> <span class="mf">48.</span><span class="p">],</span>
               <span class="p">[</span><span class="mf">25.</span><span class="p">,</span> <span class="mf">91.</span> <span class="p">,</span><span class="mf">55.</span><span class="p">,</span> <span class="mf">67.</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[ 5.  7.  5.  9.]
 [ 5. 14.  7. 10.]
 [20. 77. 41. 48.]
 [25. 91. 55. 67.]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">P</span><span class="p">,</span><span class="n">L</span><span class="p">,</span><span class="n">U</span><span class="o">=</span><span class="n">sl</span><span class="o">.</span><span class="n">lu</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="c1"># P here is a &#39;permutation matrix&#39; that performs swaps based upon partial pivoting</span>
<span class="nb">print</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[0. 1. 0. 0.]
 [0. 0. 0. 1.]
 [0. 0. 1. 0.]
 [1. 0. 0. 0.]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># the lower-triangular matrix</span>
<span class="nb">print</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[ 1.          0.          0.          0.        ]
 [ 0.2         1.          0.          0.        ]
 [ 0.8        -0.375       1.          0.        ]
 [ 0.2         0.375       0.33333333  1.        ]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># the upper-triangular matrix</span>
<span class="nb">print</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[ 25.          91.          55.          67.        ]
 [  0.         -11.2         -6.          -4.4       ]
 [  0.           0.          -5.25        -7.25      ]
 [  0.           0.           0.           0.66666667]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># double check that P*L*U does indeed equal A</span>
<span class="nb">print</span><span class="p">(</span><span class="n">P</span> <span class="o">@</span> <span class="n">L</span> <span class="o">@</span> <span class="n">U</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[ 5.  7.  5.  9.]
 [ 5. 14.  7. 10.]
 [20. 77. 41. 48.]
 [25. 91. 55. 67.]]
</pre></div>
</div>
</div>
</div>
<p>Looking at the form of <span class="math notranslate nohighlight">\(P\)</span> above, we can re-order the rows in advance and consider the LU decomposition of the matrix where <span class="math notranslate nohighlight">\(P=I\)</span>, as below. As we haven’t bothered implementing pivoting ourselves, check that your LU implementation recreates the <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(L\)</span> and <span class="math notranslate nohighlight">\(U\)</span> below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">25.</span> <span class="p">,</span><span class="mf">91.</span> <span class="p">,</span><span class="mf">55.</span> <span class="p">,</span><span class="mf">67.</span><span class="p">],</span>
               <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">9.</span><span class="p">],</span> 
               <span class="p">[</span><span class="mf">20.</span><span class="p">,</span> <span class="mf">77.</span><span class="p">,</span> <span class="mf">41.</span><span class="p">,</span> <span class="mf">48.</span><span class="p">],</span>
               <span class="p">[</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">14.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">,</span>  <span class="mf">10.</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[25. 91. 55. 67.]
 [ 5.  7.  5.  9.]
 [20. 77. 41. 48.]
 [ 5. 14.  7. 10.]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">P</span><span class="p">,</span><span class="n">L</span><span class="p">,</span><span class="n">U</span><span class="o">=</span><span class="n">sl</span><span class="o">.</span><span class="n">lu</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="c1"># P now should be the identity as pivoting no longer actually actions any row swaps with this A</span>
<span class="nb">print</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[1. 0. 0. 0.]
 [0. 1. 0. 0.]
 [0. 0. 1. 0.]
 [0. 0. 0. 1.]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[ 1.          0.          0.          0.        ]
 [ 0.2         1.          0.          0.        ]
 [ 0.8        -0.375       1.          0.        ]
 [ 0.2         0.375       0.33333333  1.        ]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[ 25.          91.          55.          67.        ]
 [  0.         -11.2         -6.          -4.4       ]
 [  0.           0.          -5.25        -7.25      ]
 [  0.           0.           0.           0.66666667]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">P</span> <span class="o">@</span> <span class="n">L</span> <span class="o">@</span> <span class="n">U</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[25. 91. 55. 67.]
 [ 5.  7.  5.  9.]
 [20. 77. 41. 48.]
 [ 5. 14.  7. 10.]]
</pre></div>
</div>
</div>
</div>
<div class="section" id="span-style-color-blue-exercise-6-3-partial-pivoting-span">
<h3><span style="color:blue">Exercise 6.3: Partial pivoting</span><a class="headerlink" href="#span-style-color-blue-exercise-6-3-partial-pivoting-span" title="Permalink to this headline">¶</a></h3>
<p>Implement partial pivoting.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "primer-computational-mathematics/book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./3_mathematics/numerical_methods/NM1_2020"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Imperial College London<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../../_static/js/index.js"></script>
    
  </body>
</html>