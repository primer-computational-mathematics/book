

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Chapter 0 – Introduction &#8212; ESE Jupyter Material</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".cell"
        const thebe_selector_input = ".cell_input div.highlight"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Chapter 1 – Neural Network" href="Chapter 1 -- Neural Network.html" />
    <link rel="prev" title="Machine learning" href="intro.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ESE Jupyter Material</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../../intro.html">Landing page</a>
  </li>
  <li class="">
    <a href="../../a_modules/intro.html">Modules</a>
  </li>
  <li class="">
    <a href="../../b_coding/intro.html">Coding</a>
  </li>
  <li class="">
    <a href="../../c_mathematics/intro.html">Mathematics</a>
  </li>
  <li class="">
    <a href="../../d_geosciences/intro.html">Geosciences</a>
  </li>
  <li class="active">
    <a href="../intro.html">Further resources</a>
  <ul class="nav sidenav_l2">
    <li class="">
      <a href="../Camera_Calibration.html">Camera calibration</a>
    </li>
    <li class="">
      <a href="../Cartography_Cartopy.html">Cartopy (maps)</a>
    </li>
    <li class="">
      <a href="../Dakota.html">Dakota</a>
    </li>
    <li class="">
      <a href="../Google_Earth_Engine_Foundations.html">Google Earth Engine foundations</a>
    </li>
    <li class="">
      <a href="../Google_Earth_Engine_Getting_Started_.html">Google Earth Engine getting started</a>
    </li>
    <li class="">
      <a href="../Particle_Image_Velocimetry.html">Particle image velocimetry (PIV)</a>
    </li>
    <li class="">
      <a href="../contributors_guide.html">Contributor’s guide</a>
    </li>
    <li class="">
      <a href="../UAV_Mapping/intro.html">UAV Mapping</a>
    </li>
    <li class="active">
      <a href="intro.html">Machine learning</a>
      <ul class="nav sidenav_l3">
      <li class="active">
        <a href="">Chapter 0 – Introduction</a>
      </li>
      <li class="">
        <a href="Chapter 1 -- Neural Network.html">Chapter 1 – Neural Network</a>
      </li>
      <li class="">
        <a href="Chapter 2 -- Maximum Likelihood.html">Chapter 2 – Maximum Likelihood</a>
      </li>
      <li class="">
        <a href="Chapter 3 -- Cross Entropy.html">Chapter 3 – Cross Entropy</a>
      </li>
      <li class="">
        <a href="Chapter 4 -- Cost Function.html">Chapter 4 – Cost Function</a>
      </li>
      <li class="">
        <a href="Chapter 5 -- Gradient Descent 1.html">Chapter 5 – Gradient Descent 1</a>
      </li>
      <li class="">
        <a href="Chapter 6 -- Gradient Descent 2.html">Chapter 6 – Gradient Descent 2</a>
      </li>
      <li class="">
        <a href="Chapter 7 -- Real (Non-linear) Neural Network.html">Chapter 7 – Real (Non-linear) Neural Network</a>
      </li>
      <li class="">
        <a href="Chapter 8 -- Feedforward.html">Chapter 8 – Feedforward</a>
      </li>
      <li class="">
        <a href="Chapter 9 -- Back Propagation.html">Chapter 9 – Back Propagation</a>
      </li>
      <li class="">
        <a href="Chapter 10 -- General Back Propagation.html">Chapter 10 – General Back Propagation</a>
      </li>
      <li class="">
        <a href="Chapter 11 -- Underfitting and Overfitting.html">Chapter 11 – Underfitting and Overfitting</a>
      </li>
      <li class="">
        <a href="Chapter 12 -- Early-stopping, Dropout & Mini-batch.html">Chapter 12 – Early-stopping, Dropout & Mini-batch</a>
      </li>
      <li class="">
        <a href="Chapter 13 -- Vanishing Gradient 1.html">Chapter 13 – Vanishing Gradient 1</a>
      </li>
      <li class="">
        <a href="Chapter 14 -- Vanishing Gradient 2.html">Chapter 14 – Vanishing Gradient 2</a>
      </li>
      <li class="">
        <a href="Chapter 15 -- Regularisation.html">Chapter 15 – Regularisation</a>
      </li>
      <li class="">
        <a href="Chapter 16 -- Other Activation Functions.html">Chapter 16 – Other Activation Functions</a>
      </li>
      <li class="">
        <a href="Chapter 17 -- Local Minima Trap.html">Chapter 17 – Local Minima Trap</a>
      </li>
      <li class="">
        <a href="Chapter 18 -- Softmax.html">Chapter 18 – Softmax</a>
      </li>
      <li class="">
        <a href="Chapter 19 -- Hyper-Parameters.html">Chapter 19 – Hyper-Parameters</a>
      </li>
      <li class="">
        <a href="Chapter 20 -- Coding Example.html">Chapter 20 – Coding Example</a>
      </li>
    </ul>
    </li>
  </ul>
  </li>
  <li class="">
    <a href="../../genindex.html">Index</a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/e_extra/pytorch_image_filtering_ml/Chapter 0 -- Introduction.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        <a class="issues-button"
            href="https://github.com/primer-computational-mathematics/book/issues/new?title=Issue%20on%20page%20%2Fe_extra/pytorch_image_filtering_ml/Chapter 0 -- Introduction.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/primer-computational-mathematics/book/master?urlpath=tree/notebooks/e_extra/pytorch_image_filtering_ml/Chapter 0 -- Introduction.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#classification-of-my-partners-decision" class="nav-link">Classification of My Partner’s Decision</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#classification-of-admission-data" class="nav-link">Classification of Admission Data</a>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="chapter-0-introduction">
<span id="introduction"></span><h1>Chapter 0 – Introduction<a class="headerlink" href="#chapter-0-introduction" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%javascript</span>
<span class="nx">MathJax</span><span class="p">.</span><span class="nx">Hub</span><span class="p">.</span><span class="nx">Config</span><span class="p">({</span>
    <span class="nx">TeX</span><span class="o">:</span> <span class="p">{</span> <span class="nx">equationNumbers</span><span class="o">:</span> <span class="p">{</span> <span class="nx">autoNumber</span><span class="o">:</span> <span class="s2">&quot;AMS&quot;</span> <span class="p">}</span> <span class="p">}</span>
<span class="p">});</span>
<span class="nx">MathJax</span><span class="p">.</span><span class="nx">Hub</span><span class="p">.</span><span class="nx">Queue</span><span class="p">(</span>
  <span class="p">[</span><span class="s2">&quot;resetEquationNumbers&quot;</span><span class="p">,</span> <span class="nx">MathJax</span><span class="p">.</span><span class="nx">InputJax</span><span class="p">.</span><span class="nx">TeX</span><span class="p">],</span>
  <span class="p">[</span><span class="s2">&quot;PreProcess&quot;</span><span class="p">,</span> <span class="nx">MathJax</span><span class="p">.</span><span class="nx">Hub</span><span class="p">],</span>
  <span class="p">[</span><span class="s2">&quot;Reprocess&quot;</span><span class="p">,</span> <span class="nx">MathJax</span><span class="p">.</span><span class="nx">Hub</span><span class="p">]</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
});
MathJax.Hub.Queue(
  ["resetEquationNumbers", MathJax.InputJax.TeX],
  ["PreProcess", MathJax.Hub],
  ["Reprocess", MathJax.Hub]
);
</script></div>
</div>
<p>There is enough of the introduction about machine learning, so there is no need to elaborate again. This study material helps you understand the codes that classify hand-written digits based on the classic MNIST dataset that can easily be downloaded online (mnist.pkl.gz). Here is how to load the dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">mnist_loader</span>
<span class="sd">~~~~~~~~~~~~</span>

<span class="sd">A library to load the MNIST image data.  For details of the data</span>
<span class="sd">structures that are returned, see the doc strings for ``load_data``</span>
<span class="sd">and ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the</span>
<span class="sd">function usually called by our neural network code.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1">#### Libraries</span>
<span class="c1"># Standard library</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">gzip</span>

<span class="c1"># Third-party libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">load_data</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Return the MNIST data as a tuple containing the training data,</span>
<span class="sd">    the validation data, and the test data.</span>

<span class="sd">    The ``training_data`` is returned as a tuple with two entries.</span>
<span class="sd">    The first entry contains the actual training images.  This is a</span>
<span class="sd">    numpy ndarray with 50,000 entries.  Each entry is, in turn, a</span>
<span class="sd">    numpy ndarray with 784 values, representing the 28 * 28 = 784</span>
<span class="sd">    pixels in a single MNIST image.</span>

<span class="sd">    The second entry in the ``training_data`` tuple is a numpy ndarray</span>
<span class="sd">    containing 50,000 entries.  Those entries are just the digit</span>
<span class="sd">    values (0...9) for the corresponding images contained in the first</span>
<span class="sd">    entry of the tuple.</span>

<span class="sd">    The ``validation_data`` and ``test_data`` are similar, except</span>
<span class="sd">    each contains only 10,000 images.</span>

<span class="sd">    This is a nice data format, but for use in neural networks it&#39;s</span>
<span class="sd">    helpful to modify the format of the ``training_data`` a little.</span>
<span class="sd">    That&#39;s done in the wrapper function ``load_data_wrapper()``, see</span>
<span class="sd">    below.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;mnist.pkl.gz&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
    <span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;latin1&#39;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_data_wrapper</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Return a tuple containing ``(training_data, validation_data,</span>
<span class="sd">    test_data)``. Based on ``load_data``, but the format is more</span>
<span class="sd">    convenient for use in our implementation of neural networks.</span>

<span class="sd">    In particular, ``training_data`` is a list containing 50,000</span>
<span class="sd">    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray</span>
<span class="sd">    containing the input image.  ``y`` is a 10-dimensional</span>
<span class="sd">    numpy.ndarray representing the unit vector corresponding to the</span>
<span class="sd">    correct digit for ``x``.</span>

<span class="sd">    ``validation_data`` and ``test_data`` are lists containing 10,000</span>
<span class="sd">    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional</span>
<span class="sd">    numpy.ndarry containing the input image, and ``y`` is the</span>
<span class="sd">    corresponding classification, i.e., the digit values (integers)</span>
<span class="sd">    corresponding to ``x``.</span>

<span class="sd">    Obviously, this means we&#39;re using slightly different formats for</span>
<span class="sd">    the training data and the validation / test data.  These formats</span>
<span class="sd">    turn out to be the most convenient for use in our neural network</span>
<span class="sd">    code.&quot;&quot;&quot;</span>
    <span class="n">tr_d</span><span class="p">,</span> <span class="n">va_d</span><span class="p">,</span> <span class="n">te_d</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>
    <span class="n">training_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">training_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">vectorized_result</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">training_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">training_inputs</span><span class="p">,</span> <span class="n">training_results</span><span class="p">))</span> 
    <span class="n">validation_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">validation_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">validation_inputs</span><span class="p">,</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">test_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">test_inputs</span><span class="p">,</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span> 
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">vectorized_result</span><span class="p">(</span><span class="n">j</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a 10-dimensional unit vector with a 1.0 in the jth</span>
<span class="sd">    position and zeroes elsewhere.  This is used to convert a digit</span>
<span class="sd">    (0...9) into a corresponding desired output from the neural</span>
<span class="sd">    network.&quot;&quot;&quot;</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">e</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">e</span>
</pre></div>
</div>
</div>
</div>
<p>This study material consolidates your understandings by explaining the codes line by line with the maths behind it. The reader is expected to have some basic knowledges about linear algebra and calculus, otherwise we strongly recommend you to go through these materials first (reference a github link here). Note that this material will not cover CNN (Convolutional Neural Network), GAN (Generative Adversarial Network) and RNN (Recurrent Neural Network).</p>
<div class="section" id="classification-of-my-partners-decision">
<h2>Classification of My Partner’s Decision<a class="headerlink" href="#classification-of-my-partners-decision" title="Permalink to this headline">¶</a></h2>
<p>One of the classic exmaple to get you into machine learning is a classfication example. Suppose the weekend is coming up, and my partner has heard that there’s going to be an Imperial open day. She likes Imperial, and is trying to decide whether or not to go to the open day. She might make her decision by weighing up three factors:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Factor</p></th>
<th class="head"><p>Condition</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Is the weather good?</p></td>
<td><p>Y/N</p></td>
</tr>
<tr class="row-odd"><td><p>Will I accompany my partner?</p></td>
<td><p>Y/N</p></td>
</tr>
<tr class="row-even"><td><p>Boris’ Stay Home policy?</p></td>
<td><p>Y/N</p></td>
</tr>
</tbody>
</table>
<p>This decision making process is achieved via neural network. To get started, we need to explain a type of artificial neuron called a perceptron. A perceptron takes several binary inputs <span class="math notranslate nohighlight">\(x_1\)</span>, <span class="math notranslate nohighlight">\(x_2\)</span>, … and produces a single binary output:</p>
<img src="images/perceptron.PNG" /><p>In the example shown the perceptron has three inputs, <span class="math notranslate nohighlight">\(x_1\)</span>, <span class="math notranslate nohighlight">\(x_2\)</span> and <span class="math notranslate nohighlight">\(x_3\)</span>. In general it could have more or fewer inputs. There is a simple rule to compute the output. Here we introduce weights, <span class="math notranslate nohighlight">\(w_1\)</span>, <span class="math notranslate nohighlight">\(w_2\)</span>, …, real numbers expressing the importance of the respective inputs to the output. The neuron’s output, <span class="math notranslate nohighlight">\(0\)</span> or <span class="math notranslate nohighlight">\(1\)</span>, is determined by whether the weighted sum <span class="math notranslate nohighlight">\(\sum_i w_i x_i\)</span> is less than or greater than some threshold value. Just like the weights, the threshold is a real number which is a parameter of the neuron. To put it in more precise algebraic terms:</p>
<div class="math notranslate nohighlight" id="equation-eq0-1">
<span class="eqno">(184)<a class="headerlink" href="#equation-eq0-1" title="Permalink to this equation">¶</a></span>\[\begin{split}  output = \begin{cases} 
      0 &amp; if \; \sum_i w_i x_i \leq threshold \\
      1 &amp; if \; \sum_i w_i x_i &gt; threshold
      \label{segment_eq}
   \end{cases}
\end{split}\]</div>
<p>That’s the basic mathematical model. A way to think about the perceptron is that it’s a device that makes decisions by weighing up evidence. For instance, we’d have <span class="math notranslate nohighlight">\(x_1=1\)</span> if the weather is good, and <span class="math notranslate nohighlight">\(x_1=0\)</span> if the weather is bad. Similarly, <span class="math notranslate nohighlight">\(x_2=1\)</span> if I want to accompany my partner, and <span class="math notranslate nohighlight">\(x_2=0\)</span> if not. And similarly again for <span class="math notranslate nohighlight">\(x_3\)</span> and stay home policy.</p>
<p>Now, suppose my partner absolutely adores Imperial, so much so that she/he is happy to go to the open day even if I was uninterested and the Boris said “Please stay at home and save lives” many many times. Or perhaps she/he really loathes bad weather, and there’s no way she’d go to the open day if the weather is bad. We can use perceptrons to model this kind of decision-making. One way to do this is to choose a weight <span class="math notranslate nohighlight">\(w_1=6\)</span> for the weather, and <span class="math notranslate nohighlight">\(w_2=2\)</span> and <span class="math notranslate nohighlight">\(w_3=2\)</span> for the other conditions. The larger value of <span class="math notranslate nohighlight">\(w_1\)</span> indicates that the weather matters a lot to my partner, much more than whether I join or the stay home policy. Finally, suppose we choose a threshold of 5 for the perceptron. With these choices, the perceptron implements the desired decision-making model, outputting 1 whenever the weather is good, and 0 whenever the weather is bad. It makes no difference to the output whether I want to join my partner, or whether Boris’ spank those who do not stay at homes.</p>
<p>By varying the weights and the threshold, we can get different models of decision-making. For example, suppose we instead chose a threshold of 3. Then the perceptron would decide that my partner should go to the festival whenever the weather was good or when both the stay home policy is lifted and I want to join her/him. In other words, it’d be a different model of decision-making. Dropping the threshold means she/he is more willing to go to the festival under the same 3 circumstances.</p>
<p>The key, however, is to find the weights <span class="math notranslate nohighlight">\(w\)</span> and bias <span class="math notranslate nohighlight">\(b\)</span> term in her/his mind as we do not know them in advanced. Maybe she/he hates me so <span class="math notranslate nohighlight">\(w_2 = 0\)</span> or maybe she/he is really picky <span class="math notranslate nohighlight">\(b = 100\)</span>. We don’t know. But that’s the whole point of machine learning, to know those values to some extent.</p>
</div>
<div class="section" id="classification-of-admission-data">
<h2>Classification of Admission Data<a class="headerlink" href="#classification-of-admission-data" title="Permalink to this headline">¶</a></h2>
<p>Here is another example to get you into the world of Machine Learning. Suppose the university admission is dependent on two factors: <span class="math notranslate nohighlight">\(\boldsymbol SAT\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol GPA\)</span> scores. Then we can have a list of students with their application details who applied to one of the best universities in the universe, the University of Jianou.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>SAT</p></th>
<th class="head"><p>GPA</p></th>
<th class="head"><p>Offer?</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>800</p></td>
<td><p>3.95</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>710</p></td>
<td><p>2.7</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>750</p></td>
<td><p>3.4</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>690</p></td>
<td><p>3.82</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>600</p></td>
<td><p>4.00</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
</tr>
</tbody>
</table>
<p>The University of Jianou is founded at the end of 2019 so the admission data in 2020 can be regarded as the norm of all the admission data. We want to build a model, based on the 2020 data, to predict if Barron Trump can make it into Jianou University with his scores.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>SAT</p></th>
<th class="head"><p>GPA</p></th>
<th class="head"><p>Offer?</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>530</p></td>
<td><p>1.6</p></td>
<td><p>?</p></td>
</tr>
</tbody>
</table>
<p>For human beings, it is fairly easy to have a sense of feeling of whether this kid can make it into the top university with such low grades. However, this sense of feeling is extremely hard for computer to understand. Our aim is to train the computer model to have this sense of feeling (potentially better than us) to make predictions.</p>
<p>Mathematically, we can express SAT, GPA and offer result as <span class="math notranslate nohighlight">\(x_1\)</span>, <span class="math notranslate nohighlight">\(x_2\)</span> and <span class="math notranslate nohighlight">\(y\)</span>. <span class="math notranslate nohighlight">\(y\)</span> is binary as in it is <span class="math notranslate nohighlight">\(0\)</span> when <span class="math notranslate nohighlight">\(y=N\)</span> and <span class="math notranslate nohighlight">\(1\)</span> when <span class="math notranslate nohighlight">\(y=Y\)</span>. In a sense, we can have the following table that is a quantified version of the admission data.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p><span class="math notranslate nohighlight">\(x_1\)</span></p></th>
<th class="head"><p><span class="math notranslate nohighlight">\(x_2\)</span></p></th>
<th class="head"><p>y</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>800</p></td>
<td><p>3.95</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>710</p></td>
<td><p>2.7</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>750</p></td>
<td><p>3.4</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>690</p></td>
<td><p>3.82</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>600</p></td>
<td><p>4.00</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
</tr>
</tbody>
</table>
<img src="images/SAT_GPA.PNG"/>
<center>Figure 1.1:  Visualisation of SAT and GPA; the red dot representsyvalue being Y and bluetriangle meansyvalue being N.<p>We realise that the students with higher GPA and higher SAT grades are more likely to be accepted, or the group of red dots in the upper right corner. In contrast, the students in the lower left are all rejected. There seems to be a line that separates the two groups. We can express the equation of such line as</p>
<div class="math notranslate nohighlight" id="equation-eq0-2">
<span class="eqno">(185)<a class="headerlink" href="#equation-eq0-2" title="Permalink to this equation">¶</a></span>\[
w_1 x_1 + w_2 x_2 + b = 0
\]</div>
<p>where <span class="math notranslate nohighlight">\(w_1\)</span> and <span class="math notranslate nohighlight">\(w_2\)</span> are weights, meaning how important their corresponding <span class="math notranslate nohighlight">\(x\)</span>s are; the bigger the <span class="math notranslate nohighlight">\(w_1\)</span> the more important SAT in the admission process and vice versa.</p>
<p>The trick is to find the <span class="math notranslate nohighlight">\(w_1\)</span> and <span class="math notranslate nohighlight">\(w_2\)</span> that best separates the two groups.</p>
<p>Based on Figure 1.1, we know that Barron Trump will receive an offer if</p>
<div class="math notranslate nohighlight" id="equation-eq0-3">
<span class="eqno">(186)<a class="headerlink" href="#equation-eq0-3" title="Permalink to this equation">¶</a></span>\[
w_1 x_1 + w_2 x_2 + b &lt; 0
\]</div>
<p>and will not receive an offer if</p>
<div class="math notranslate nohighlight" id="equation-eq0-4">
<span class="eqno">(187)<a class="headerlink" href="#equation-eq0-4" title="Permalink to this equation">¶</a></span>\[
w_1 x_1 + w_2 x_2 + b &lt; 0
\]</div>
<p>This is such a common used equation, so we can give it a general form</p>
<div class="math notranslate nohighlight" id="equation-eq0-5">
<span class="eqno">(188)<a class="headerlink" href="#equation-eq0-5" title="Permalink to this equation">¶</a></span>\[
h(\vec{x}) = w_1 x_1 + w_2 x_2 + ... + b
\]</div>
<p>To summarize his admission result, we can have the following equation (which is the same as equation <a class="reference internal" href="#equation-eq0-1">(184)</a>).</p>
<div class="math notranslate nohighlight" id="equation-eq0-6">
<span class="eqno">(189)<a class="headerlink" href="#equation-eq0-6" title="Permalink to this equation">¶</a></span>\[\begin{split}  \hat{y} = \begin{cases} 
      0 &amp; if \; h(\vec{x}) \leq 0 \\
      1 &amp; if \; h(\vec{x})  &gt; 0
   \end{cases}
\end{split}\]</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "primer-computational-mathematics/book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./e_extra/pytorch_image_filtering_ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">Machine learning</a>
    <a class='right-next' id="next-link" href="Chapter 1 -- Neural Network.html" title="next page">Chapter 1 – Neural Network</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Imperial College London<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
  </body>
</html>