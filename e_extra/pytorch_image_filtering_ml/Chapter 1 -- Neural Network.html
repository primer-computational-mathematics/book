

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Chapter 1 – Neural Network &#8212; ESE Jupyter Material</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/mystnb.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".cell"
        const thebe_selector_input = ".cell_input div.highlight"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Chapter 2 – Maximum Likelihood" href="Chapter 2 -- Maximum Likelihood.html" />
    <link rel="prev" title="Chapter 0 – Introduction" href="Chapter 0 -- Introduction.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">ESE Jupyter Material</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../../intro.html">Landing page</a>
  </li>
  <li class="">
    <a href="../../a_modules/intro.html">Modules</a>
  </li>
  <li class="">
    <a href="../../b_coding/intro.html">Coding</a>
  </li>
  <li class="">
    <a href="../../c_mathematics/intro.html">Mathematics</a>
  </li>
  <li class="">
    <a href="../../d_geosciences/intro.html">Geosciences</a>
  </li>
  <li class="active">
    <a href="../intro.html">Further resources</a>
  <ul class="nav sidenav_l2">
    <li class="">
      <a href="../Camera_Calibration.html">Camera calibration</a>
    </li>
    <li class="">
      <a href="../Cartography_Cartopy.html">Cartopy (maps)</a>
    </li>
    <li class="">
      <a href="../Dakota.html">Dakota</a>
    </li>
    <li class="">
      <a href="../Google_Earth_Engine_Foundations.html">Google Earth Engine foundations</a>
    </li>
    <li class="">
      <a href="../Google_Earth_Engine_Getting_Started_.html">Google Earth Engine getting started</a>
    </li>
    <li class="">
      <a href="../Particle_Image_Velocimetry.html">Particle image velocimetry (PIV)</a>
    </li>
    <li class="">
      <a href="../UAV_Mapping/intro.html">UAV Mapping</a>
    </li>
    <li class="active">
      <a href="intro.html">Machine Learning</a>
      <ul class="nav sidenav_l3">
      <li class="">
        <a href="Chapter 0 -- Introduction.html">Chapter 0 – Introduction</a>
      </li>
      <li class="active">
        <a href="">Chapter 1 – Neural Network</a>
      </li>
      <li class="">
        <a href="Chapter 2 -- Maximum Likelihood.html">Chapter 2 – Maximum Likelihood</a>
      </li>
      <li class="">
        <a href="Chapter 3 -- Cross Entropy.html">Chapter 3 – Cross Entropy</a>
      </li>
      <li class="">
        <a href="Chapter 4 -- Cost Function.html">Chapter 4 – Cost Function</a>
      </li>
      <li class="">
        <a href="Chapter 5 -- Gradient Descent 1.html">Chapter 5 – Gradient Descent 1</a>
      </li>
      <li class="">
        <a href="Chapter 6 -- Gradient Descent 2.html">Chapter 6 – Gradient Descent 2</a>
      </li>
      <li class="">
        <a href="Chapter 7 -- Real (Non-linear) Neural Network.html">Chapter 7 – Real (Non-linear) Neural Network</a>
      </li>
      <li class="">
        <a href="Chapter 8 -- Feedforward.html">Chapter 8 – Feedforward</a>
      </li>
      <li class="">
        <a href="Chapter 9 -- Back Propagation.html">Chapter 9 – Back Propagation</a>
      </li>
      <li class="">
        <a href="Chapter 10 -- General Back Propagation.html">Chapter 10 – General Back Propagation</a>
      </li>
      <li class="">
        <a href="Chapter 11 -- Underfitting and Overfitting.html">Chapter 11 – Underfitting and Overfitting</a>
      </li>
      <li class="">
        <a href="Chapter 12 -- Early-stopping, Dropout & Mini-batch.html">Chapter 12 – Early-stopping, Dropout & Mini-batch</a>
      </li>
      <li class="">
        <a href="Chapter 13 -- Vanishing Gradient 1.html">Chapter 13 – Vanishing Gradient 1</a>
      </li>
      <li class="">
        <a href="Chapter 14 -- Vanishing Gradient 2.html">Chapter 14 – Vanishing Gradient 2</a>
      </li>
      <li class="">
        <a href="Chapter 15 -- Regularisation.html">Chapter 15 – Regularisation</a>
      </li>
      <li class="">
        <a href="Chapter 16 -- Other Activation Functions.html">Chapter 16 – Other Activation Functions</a>
      </li>
      <li class="">
        <a href="Chapter 17 -- Local Minima Trap.html">Chapter 17 – Local Minima Trap</a>
      </li>
      <li class="">
        <a href="Chapter 18 -- Softmax.html">Chapter 18 – Softmax</a>
      </li>
      <li class="">
        <a href="Chapter 19 -- Hyper-Parameters.html">Chapter 19 – Hyper-Parameters</a>
      </li>
      <li class="">
        <a href="Chapter 20 -- Coding Example.html">Chapter 20 – Coding Example</a>
      </li>
    </ul>
    </li>
  </ul>
  </li>
  <li class="">
    <a href="../../genindex.html">Index</a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/e_extra/pytorch_image_filtering_ml/Chapter 1 -- Neural Network.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        
        <a class="issues-button"
            href="https://github.com/primer-computational-mathematics/book/issues/new?title=Issue%20on%20page%20%2Fe_extra/pytorch_image_filtering_ml/Chapter 1 -- Neural Network.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/primer-computational-mathematics/book/master?urlpath=tree/notebooks/e_extra/pytorch_image_filtering_ml/Chapter 1 -- Neural Network.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p>(Neural_Network) =</p>
<div class="section" id="chapter-1-neural-network">
<h1>Chapter 1 – Neural Network<a class="headerlink" href="#chapter-1-neural-network" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">javascript</span>
<span class="n">MathJax</span><span class="o">.</span><span class="n">Hub</span><span class="o">.</span><span class="n">Config</span><span class="p">({</span>
    <span class="n">TeX</span><span class="p">:</span> <span class="p">{</span> <span class="n">equationNumbers</span><span class="p">:</span> <span class="p">{</span> <span class="n">autoNumber</span><span class="p">:</span> <span class="s2">&quot;AMS&quot;</span> <span class="p">}</span> <span class="p">}</span>
<span class="p">});</span>
<span class="n">MathJax</span><span class="o">.</span><span class="n">Hub</span><span class="o">.</span><span class="n">Queue</span><span class="p">(</span>
  <span class="p">[</span><span class="s2">&quot;resetEquationNumbers&quot;</span><span class="p">,</span> <span class="n">MathJax</span><span class="o">.</span><span class="n">InputJax</span><span class="o">.</span><span class="n">TeX</span><span class="p">],</span>
  <span class="p">[</span><span class="s2">&quot;PreProcess&quot;</span><span class="p">,</span> <span class="n">MathJax</span><span class="o">.</span><span class="n">Hub</span><span class="p">],</span>
  <span class="p">[</span><span class="s2">&quot;Reprocess&quot;</span><span class="p">,</span> <span class="n">MathJax</span><span class="o">.</span><span class="n">Hub</span><span class="p">]</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/javascript">MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" } }
});
MathJax.Hub.Queue(
  ["resetEquationNumbers", MathJax.InputJax.TeX],
  ["PreProcess", MathJax.Hub],
  ["Reprocess", MathJax.Hub]
);
</script></div>
</div>
<p>Obviously, the perceptron isn’t a complete model of human decision-making! But what the example illustrates is how a perceptron can weigh up different kinds of evidence in order to make decisions. And it should seem plausible that a complex network of perceptrons could make quite subtle decisions:</p>
<img src="images/advanced_NeuralNetwork.PNG">
<center>Figure 1.2:  Multilayer Perceptrons<p>In this network, the first column of perceptrons - what we’ll call the first layer of perceptrons - is making three very simple decisions, by weighing the input evidence. What about the perceptrons in the second layer? Each of those perceptrons is making a decision by weighing up the results from the first layer of decision-making. In this way a perceptron in the second layer can make a decision at a more complex and more abstract level than perceptrons in the first layer. And even more complex decisions can be made by the perceptron in the third layer. In this way, a many-layer network of perceptrons can engage in sophisticated decision making.</p>
<p>Incidentally, when I defined perceptrons I said that a perceptron has just a single output. In the network above the perceptrons look like they have multiple outputs. In fact, they’re still single output. The multiple output arrows are merely a useful way of indicating that the output from a perceptron is being used as the input to several other perceptrons. It’s less unwieldy than drawing a single output line which then splits.</p>
<p>There is another way of representing the neural network. The following structure has one additional neuron for the bias term. The value of it is always <span class="math notranslate nohighlight">\(1\)</span>.</p>
<img src="images/discretePerceptron.PNG" width="600">
<center>Figure 1.3:  Discrete Perceptron<p>This is because we would end up the equation we wanted:</p>
<p>\begin{equation}
h(\vec{x}) = w_1<em>x_1 + w_2</em>x_2+ w_3 * x_3 + 1*b
\end{equation}</p>
<p>Now, in the previous two examples, we have used the step function as the activation function <span class="math notranslate nohighlight">\(f(h)\)</span>. The function returns 1 when activated and 0 if not activated. This is saying the result is always binary (0 or 1). Succeed completely or utterly failure, getting enrolled or being rejected……This is called the discrete perceptron.</p>
<p>However, this is not as good as it can be. A student scoring 1 mark below the admission line should not receive the same prediction as the student who got 0 in the exam. Although they should all get rejected, the better prediction should give student A a higher chance of getting into the university as he is so close, and should give student B a very low predicted probability as he puts zero effort in revision.</p>
<p>Another way of thinking this is that in the discrete perceptron model, if the neural network predicts a result to be 1 but actually it is 0, then we can easily replace the 1 with 0 to modify it. However, in a complex neural network, not every result can or should be replaced and modified (over-fitting, explained later). What we want is to make sure the network predicts the result mostly right without making some big mistakes! So we define a new concept called the cost function, which is how far away the predicted result is from the actual result. In that case, we just reduce the degree of how far away we are to improve the model.</p>
<p>The third reason we need to smooth out the step function is that we need to use derivatives to find the minimums, a step function is not derivable.</p>
<p>Anyway, those three thinking lead us to a new activation function – the sigmoid function:</p>
<p>\begin{equation}
\sigma (z) = \frac{1}{1+e^{-z}}
\end{equation}</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># make the figure be plotted at the centre</span>
<span class="kn">from</span> <span class="nn">IPython.core.display</span> <span class="kn">import</span> <span class="n">HTML</span>
<span class="n">HTML</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">&lt;style&gt;</span>
<span class="s2">.output_png {</span>
<span class="s2">    display: table-cell;</span>
<span class="s2">    text-align: center;</span>
<span class="s2">    vertical-align: middle;</span>
<span class="s2">}</span>
<span class="s2">&lt;/style&gt;</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<style>
.output_png {
    display: table-cell;
    text-align: center;
    vertical-align: middle;
}
</style>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">N</span>  <span class="o">=</span> <span class="mi">100</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$z$&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$sigma(z)$&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Figure 1.4 Sigma function&#39;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Chapter 1 -- Neural Network_17_0.png" src="../../_images/Chapter 1 -- Neural Network_17_0.png" />
</div>
</div>
<p>This shape is a smoothed out version of a step function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
   
    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span> 
    <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$z$&#39;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Figure 1.5 Step function&#39;</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Chapter 1 -- Neural Network_19_0.png" src="../../_images/Chapter 1 -- Neural Network_19_0.png" />
</div>
</div>
<p>To put it all a little more explicitly, the output of a sigmoid neuron with inputs <span class="math notranslate nohighlight">\(x_1\)</span>, <span class="math notranslate nohighlight">\(x_2\)</span>, …, weights <span class="math notranslate nohighlight">\(w_1\)</span>, <span class="math notranslate nohighlight">\(w_2\)</span>,… , and bias <span class="math notranslate nohighlight">\(b\)</span> is</p>
<p>\begin{equation}
\frac{1}{1+exp(-\sum_i w_i x_i -b)}
\end{equation}</p>
<p>To understand the similarity to the perceptron model, suppose <span class="math notranslate nohighlight">\(z≡wx+b\)</span> is a large positive number. Then <span class="math notranslate nohighlight">\(e^z\approx 0\)</span> and so <span class="math notranslate nohighlight">\(\sigma(z) \approx
1\)</span>. In other words, when z=w⋅x+b is large and positive, the output from the sigmoid neuron is approximately 1, just as it would have been for a perceptron. Suppose on the other hand that <span class="math notranslate nohighlight">\(z=wx+\)</span>b is very negative. Then <span class="math notranslate nohighlight">\(e^z-&gt;\infty\)</span>, and <span class="math notranslate nohighlight">\(\sigma(z) \approx 0\)</span>. So when <span class="math notranslate nohighlight">\(z=w⋅x+b\)</span> is very negative, the behaviour of a sigmoid neuron also closely approximates a perceptron. It’s only when <span class="math notranslate nohighlight">\(wx+b\)</span> is of modest size that there’s much deviation from the perceptron model.</p>
<p>The smoothness of <span class="math notranslate nohighlight">\(\sigma\)</span> means that small changes <span class="math notranslate nohighlight">\(\Delta w_j\)</span> in the weights and <span class="math notranslate nohighlight">\(\Delta b\)</span> in the bias will produce a small change <span class="math notranslate nohighlight">\(\Delta\)</span> output in the output from the neuron. In fact, calculus tells us that <span class="math notranslate nohighlight">\(\Delta\)</span> output is well approximated by</p>
<p>\begin{equation}
\Delta output \approx \sum_i \frac{\delta output}{\delta w_i} \Delta w_i +\frac{\delta output}{\delta b_i} \Delta b_i
\end{equation}</p>
<img src="images/discreteVsQuantify.PNG" width="600">
<center>Figure 1.6:  Discrete vs. Quantify Perceptron</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "primer-computational-mathematics/book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./e_extra/pytorch_image_filtering_ml"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="Chapter 0 -- Introduction.html" title="previous page">Chapter 0 – Introduction</a>
    <a class='right-next' id="next-link" href="Chapter 2 -- Maximum Likelihood.html" title="next page">Chapter 2 – Maximum Likelihood</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Imperial College London<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
  </body>
</html>