{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(greedy_algorithms)=\n",
    "# Greedy Algorithms\n",
    "``` {index} Greedy Algorithms\n",
    "```\n",
    "\n",
    "Greedy Algorithms is one of the paradigms of algorithmic problem solving. All greedy algorithms share the assumption that local optimal steps lead to the globally optimal solution. Quite surprisingly, this is often a valid assertion. \n",
    "\n",
    "If you want to have a good grasp on the topic, please have a look at [Dynamic Programming](https://primer-computational-mathematics.github.io/book/b_coding/Fundamentals%20of%20Computer%20Science/4_Dynamic_Programming.html#dynamic-programming) section beforehand.\n",
    "\n",
    "\n",
    "\n",
    "## Basic Examples\n",
    "\n",
    "* **Greedy Scheduling** We are given a list `timeslots` wih each element being a tuple \\\\((s,f)\\\\) where \\\\(s\\\\) is the starting time of the event and \\\\(f\\\\) its the finish time. We need to choose a subset of non-overlapping `timeslots` that has the most elements. Return the number of elements in that subset.\n",
    "\n",
    "First, let us assume that `timeslots` is sorted by \\\\(f\\\\) (non-decreasing).\n",
    "\n",
    "Let us show that the problem has an optimal substructure. Let \\\\(S_{ij}\\\\) denote a set of events which start after event \\\\(a_i\\\\) and finish before the event \\\\(a_j\\\\) and \\\\(A_{ij}\\\\) be the optimal subset of \\\\(S_{ij}\\\\). We can see that \\\\(A_{ij} = A_{ik} + a_k + A_{kj}\\\\) for \\\\(i\\leq k \\leq j\\\\). Now \\\\(A_{ik}\\\\) is the solution for  \\\\(A_{ik}\\\\) and \\\\(A_{kj}\\\\) solves \\\\(S_{kj}\\\\). These are two independent subproblems, so the problem has an optimal substructure.\n",
    "\n",
    "Now, you can have a thought how, based on this information, one can implement Dynamic solution. However, let us jump straight into Greedy:\n",
    "\n",
    "Our hypothesis is to always choose the task that ends the earliest. We will show that (some optimal) \\\\(A_{ij}\\\\) always contains the earliest ending task \\\\(a_m\\\\) of \\\\(\\\\(S_{ij}\\\\). Then, inductively, we know that this leads to globally optimal arrangement. \n",
    "\n",
    "**Proof**: Let \\\\(a_n\\\\) be the earliest ending task in \\\\(A_{ij}\\\\) (does not have to be the same as \\\\(a_m\\\\)). If \\\\(a_n == a_m\\\\) then we are done. Otherwise, it is possible to swap \\\\(a_n\\\\) with \\\\(a_m\\\\) keeping \\\\(A_{ij}\\\\) valid. As \\\\(A_{ij}\\\\) was optimal, such swap still makes it optimal. \n",
    "\n",
    "Have a look at the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def greedyScheduling(timeslots):\n",
    "    timeslots.sort(key = lambda x: x[1])\n",
    "    #edge case\n",
    "    if not len(timeslots):\n",
    "        return 0\n",
    "    # setting up the initial vars\n",
    "    curr = timeslots[0]\n",
    "    res = 1 \n",
    "    for i in range(1,len(timeslots)):\n",
    "        if curr[1] <= timeslots[i][0]:\n",
    "            curr = timeslots[i]\n",
    "            res += 1       \n",
    "    return res\n",
    "\n",
    "# brute force for testing\n",
    "def bruteForce(timeslots):\n",
    "    res = 0\n",
    "    # all combinations of the elements\n",
    "    for i in range(2**len(timeslots)):\n",
    "        temp = 0\n",
    "        already_chosen = []\n",
    "        for j in range(len(timeslots)):\n",
    "            if (i >> j) & 1:\n",
    "                s, e = timeslots[j]\n",
    "                temp += 1\n",
    "                already_chosen.append(timeslots[j])\n",
    "            # checking if a valid combination of timeslots                 \n",
    "            for k in range(len(already_chosen)-1):\n",
    "                if not (s >= already_chosen[k][1] or e <= already_chosen[k][0]):\n",
    "                    temp = 0\n",
    "                    break                 \n",
    "        res = max(temp, res)\n",
    "    return res    \n",
    "    \n",
    "# testing\n",
    "for _ in range(20):\n",
    "    timeslots = []    \n",
    "    for _ in range(12):\n",
    "        s = randint(0,99)\n",
    "        e = randint(s+1,100)\n",
    "        timeslots.append((s,e))\n",
    "    br = bruteForce(timeslots)\n",
    "    gr = greedyScheduling(timeslots)  \n",
    "    assert gr == br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time complexity is \\\\(O(nlog(n))\\\\) but this is due to sorting the events. If the events were sorted initially it would be \\\\(O(n)\\\\).\n",
    "\n",
    "------------------\n",
    "* **Cover a set of points with given length intervals** You are given a list `points` of \\\\(x\\\\)-coordinates of points and `l` - the lenght of the invterval. How many intervals do we need to cover the points?\n",
    "\n",
    "\n",
    "Let \\\\(A_{ij}\\\\) denote the optimal set of intervals that cover the points. Take the element from this set \\\\((s_k,e_k\\\\) then \\\\(A_{ij} = A_{ik} + a_k + A_{kj}\\\\). Similair analysis as in the previous example leads to the conclusion that the problam has an optimal substructure.\n",
    "\n",
    "Now let us show that greedy choices lead to the optimal solution:\n",
    "\n",
    "Let us sort the points in the non-decreasing order. We insert an interval where the first begins (an can cover other points) and continue such insertion until we are done.\n",
    "\n",
    "Now, consider the optimal solution \\\\(A_{ij}\\\\) and its firt interval. If it does start where the first point, we can replace it with such interval and the solution remains optimal. Done!\n",
    "\n",
    "Here is the code implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervals(points,l):\n",
    "    # sort the points\n",
    "    points.sort()\n",
    "    if not len(points):\n",
    "        return 0\n",
    "    # set the initial vars\n",
    "    res = 1\n",
    "    border = points[0] + l\n",
    "    # go through the list\n",
    "    for i in range(1,len(points)):\n",
    "        if points[i] > border:\n",
    "            res += 1\n",
    "            border = points[i] + l      \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly depending whether the `points` are sorted we have \\\\(O(nlog(n))\\\\) or \\\\(O(n)\\\\).\n",
    "\n",
    "## Conditions needed for Greedy Solution\n",
    "\n",
    "There are two conditions which need to be met for the Greedy solution to work:\n",
    "\n",
    "1) **Optimal substructure**: the problem should be expressed in terms of independent subproblems, just like in [Dynamic Programming]!(https://primer-computational-mathematics.github.io/book/b_coding/Fundamentals%20of%20Computer%20Science/4_Dynamic_Programming.html#dynamic-programming).\n",
    "\n",
    "2) **Greedy choice leads to optimal solution**: This is usually done by the *copy and paste* argument that shows that there exists an optimal solution that involves the proposed Greedy hypothesis. It has a inductive flavour, which means that the Greedy choice leave us with the same *smaller* problem. You can assume that the input is sorted somehow, it might be very helpful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Examples\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
